Requirement already satisfied: torchvision in ./.local/lib/python3.7/site-packages (0.5.0)Requirement already satisfied: numpy in ./.local/lib/python3.7/site-packages (from torchvision) (1.18.1)Requirement already satisfied: torch==1.4.0 in ./.local/lib/python3.7/site-packages (from torchvision) (1.4.0)Requirement already satisfied: six in /apps/skylake/software/Python/3.7.4-GCCcore-8.3.0/lib/python3.7/site-packages (from torchvision) (1.12.0)Requirement already satisfied: pillow>=4.1.1 in ./.local/lib/python3.7/site-packages (from torchvision) (7.0.0)Requirement already satisfied: scipy in ./.local/lib/python3.7/site-packages (1.4.1)Requirement already satisfied: numpy>=1.13.3 in ./.local/lib/python3.7/site-packages (from scipy) (1.18.1)###########################################################################################################{'use_cuda': True, 'peregrine': True, 'include_visuals': False, 'normalise': False, 'load_from_memory': False, 'pretrain': True, 'batch_size': 4, 'workers': 2, 'model_archi': 0, 'trainset_size': 20000, 'epochs': 5, 'learning_rate': 0.001, 'momentum': 0, 'weight_decay': 0, 'optimizer_choice': 1}Namespace(batch_size=4, epochs=5, include_visuals=False, learning_rate=0.001, load_from_memory=False, model_archi=0, momentum=0, normalise=False, optimizer_choice=1, peregrine=True, pretrain=True, trainset_size=20000, use_cuda=True, weight_decay=0, workers=2)Files already downloaded and verifiedFiles already downloaded and verifiedcuda:012500  dog  ship  ship horse['alexnet', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'googlenet', 'inception_v3', 'mnasnet0_5', 'mnasnet0_75', 'mnasnet1_0', 'mnasnet1_3', 'mobilenet_v2', 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50', 'resnext101_32x8d', 'resnext50_32x4d', 'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0', 'shufflenet_v2_x1_5', 'shufflenet_v2_x2_0', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'wide_resnet101_2', 'wide_resnet50_2']Model alexnet LoadedAlexNet(  (features): Sequential(    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))    (1): ReLU(inplace=True)    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))    (4): ReLU(inplace=True)    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (7): ReLU(inplace=True)    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (9): ReLU(inplace=True)    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (11): ReLU(inplace=True)    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)  )  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))  (classifier): Sequential(    (0): Dropout(p=0.5, inplace=False)    (1): Linear(in_features=9216, out_features=4096, bias=True)    (2): ReLU(inplace=True)    (3): Dropout(p=0.5, inplace=False)    (4): Linear(in_features=4096, out_features=4096, bias=True)    (5): ReLU(inplace=True)    (6): Linear(in_features=4096, out_features=10, bias=True)  ))Model alexnet ReshapedSending model to GPULearning Rate: 0.001, Weight Decay: 0, Momentum: 0Defined <class 'torch.optim.sgd.SGD'> OptimizerStarting Training at 1582571125.0846467Traceback (most recent call last):  File "./main.py", line 395, in <module>    test(model_names[model_archi])  File "./main.py", line 225, in test    outputs = model(inputs)  File "/home/s4091221/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__    result = self.forward(*input, **kwargs)  File "/home/s4091221/.local/lib/python3.7/site-packages/torchvision/models/alexnet.py", line 45, in forward    x = self.features(x)  File "/home/s4091221/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__    result = self.forward(*input, **kwargs)  File "/home/s4091221/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward    input = module(input)  File "/home/s4091221/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__    result = self.forward(*input, **kwargs)  File "/home/s4091221/.local/lib/python3.7/site-packages/torch/nn/modules/pooling.py", line 141, in forward    self.return_indices)  File "/home/s4091221/.local/lib/python3.7/site-packages/torch/_jit_internal.py", line 181, in fn    return if_false(*args, **kwargs)  File "/home/s4091221/.local/lib/python3.7/site-packages/torch/nn/functional.py", line 488, in _max_pool2d    input, kernel_size, stride, padding, dilation, ceil_mode)RuntimeError: Given input size: (256x1x1). Calculated output size: (256x0x0). Output size is too small###########################################################################################################{'use_cuda': True, 'peregrine': True, 'include_visuals': False, 'normalise': False, 'load_from_memory': False, 'pretrain': True, 'batch_size': 4, 'workers': 2, 'model_archi': 5, 'trainset_size': 20000, 'epochs': 5, 'learning_rate': 0.001, 'momentum': 0, 'weight_decay': 0, 'optimizer_choice': 1}Namespace(batch_size=4, epochs=5, include_visuals=False, learning_rate=0.001, load_from_memory=False, model_archi=5, momentum=0, normalise=False, optimizer_choice=1, peregrine=True, pretrain=True, trainset_size=20000, use_cuda=True, weight_decay=0, workers=2)Files already downloaded and verifiedFiles already downloaded and verifiedcuda:012500 frog  frog   car   cat['alexnet', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'googlenet', 'inception_v3', 'mnasnet0_5', 'mnasnet0_75', 'mnasnet1_0', 'mnasnet1_3', 'mobilenet_v2', 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50', 'resnext101_32x8d', 'resnext50_32x4d', 'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0', 'shufflenet_v2_x1_5', 'shufflenet_v2_x2_0', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'wide_resnet101_2', 'wide_resnet50_2']Model googlenet LoadedGoogLeNet(  (conv1): BasicConv2d(    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  )  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)  (conv2): BasicConv2d(    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  )  (conv3): BasicConv2d(    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  )  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)  (inception3a): Inception(    (branch1): BasicConv2d(      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)    )    (branch2): Sequential(      (0): BasicConv2d(        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )      (1): BasicConv2d(        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )    (branch3): Sequential(      (0): BasicConv2d(        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )      (1): BasicConv2d(        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )    (branch4): Sequential(      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)      (1): BasicConv2d(        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )  )  (inception3b): Inception(    (branch1): BasicConv2d(      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)    )    (branch2): Sequential(      (0): BasicConv2d(        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )      (1): BasicConv2d(        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )    (branch3): Sequential(      (0): BasicConv2d(        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )      (1): BasicConv2d(        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )    (branch4): Sequential(      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)      (1): BasicConv2d(        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )  )  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)  (inception4a): Inception(    (branch1): BasicConv2d(      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)    )    (branch2): Sequential(      (0): BasicConv2d(        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )      (1): BasicConv2d(        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )    (branch3): Sequential(      (0): BasicConv2d(        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )      (1): BasicConv2d(        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )    (branch4): Sequential(      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)      (1): BasicConv2d(        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )  )  (inception4b): Inception(    (branch1): BasicConv2d(      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)    )    (branch2): Sequential(      (0): BasicConv2d(        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )      (1): BasicConv2d(        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )    (branch3): Sequential(      (0): BasicConv2d(        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )      (1): BasicConv2d(        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )    (branch4): Sequential(      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)      (1): BasicConv2d(        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )  )  (inception4c): Inception(    (branch1): BasicConv2d(      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)    )    (branch2): Sequential(      (0): BasicConv2d(        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )      (1): BasicConv2d(        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )    (branch3): Sequential(      (0): BasicConv2d(        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )      (1): BasicConv2d(        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )    (branch4): Sequential(      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)      (1): BasicConv2d(        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )  )  (inception4d): Inception(    (branch1): BasicConv2d(      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)    )    (branch2): Sequential(      (0): BasicConv2d(        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )      (1): BasicConv2d(        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )    (branch3): Sequential(      (0): BasicConv2d(        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )      (1): BasicConv2d(        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )    (branch4): Sequential(      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)      (1): BasicConv2d(        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )  )  (inception4e): Inception(    (branch1): BasicConv2d(      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)    )    (branch2): Sequential(      (0): BasicConv2d(        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )      (1): BasicConv2d(        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )    (branch3): Sequential(      (0): BasicConv2d(        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )      (1): BasicConv2d(        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )    (branch4): Sequential(      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)      (1): BasicConv2d(        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )  )  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)  (inception5a): Inception(    (branch1): BasicConv2d(      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)    )    (branch2): Sequential(      (0): BasicConv2d(        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )      (1): BasicConv2d(        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )    (branch3): Sequential(      (0): BasicConv2d(        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )      (1): BasicConv2d(        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )    (branch4): Sequential(      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)      (1): BasicConv2d(        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )  )  (inception5b): Inception(    (branch1): BasicConv2d(      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)    )    (branch2): Sequential(      (0): BasicConv2d(        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )      (1): BasicConv2d(        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )    (branch3): Sequential(      (0): BasicConv2d(        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )      (1): BasicConv2d(        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )    (branch4): Sequential(      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)      (1): BasicConv2d(        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)      )    )  )  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))  (dropout): Dropout(p=0.2, inplace=False)  (fc): Linear(in_features=1024, out_features=1000, bias=True)  (classifier): Linear(in_features=1024, out_features=10, bias=True))Model googlenet ReshapedSending model to GPULearning Rate: 0.001, Weight Decay: 0, Momentum: 0Defined <class 'torch.optim.sgd.SGD'> OptimizerStarting Training at 1582571134.5346832[1,   500] loss: 4.43783716.311566829681396[1,  1000] loss: 2.68374030.66101837158203[1,  1500] loss: 2.40776145.22016620635986[1,  2000] loss: 2.30227059.345380544662476[1,  2500] loss: 2.20275873.69967937469482[1,  3000] loss: 2.14246887.92975306510925[1,  3500] loss: 2.135934102.11601829528809[1,  4000] loss: 2.113141116.23151803016663[1,  4500] loss: 2.002112130.5979142189026[1,  5000] loss: 2.021848144.77588081359863[1,  5500] loss: 1.969456159.06624937057495[1,  6000] loss: 1.994106173.51472640037537[1,  6500] loss: 1.975917187.92795372009277[1,  7000] loss: 1.927005202.17985582351685[1,  7500] loss: 1.890018216.658451795578[1,  8000] loss: 1.861052230.97062706947327[1,  8500] loss: 1.842966245.3319833278656[1,  9000] loss: 1.839488259.4817442893982[1,  9500] loss: 1.820344273.6259415149689[1, 10000] loss: 1.826052288.0236382484436[1, 10500] loss: 1.872987302.248765707016[1, 11000] loss: 1.790473316.47340750694275[1, 11500] loss: 1.758145330.7563900947571[1, 12000] loss: 1.761732344.95927333831787[1, 12500] loss: 1.731317359.1675372123718Epoch [1] loss: 6665918.219074[2,   500] loss: 1.701498373.5402376651764[2,  1000] loss: 1.704782387.758624792099[2,  1500] loss: 1.717835401.92218136787415[2,  2000] loss: 1.696200416.6482036113739[2,  2500] loss: 1.682833431.02601742744446[2,  3000] loss: 1.661625445.3717098236084[2,  3500] loss: 1.676397459.75023794174194[2,  4000] loss: 1.670337474.15002942085266[2,  4500] loss: 1.616513488.57103204727173[2,  5000] loss: 1.664788503.05551743507385[2,  5500] loss: 1.657819517.5372014045715[2,  6000] loss: 1.615158532.231547832489[2,  6500] loss: 1.619483546.778347492218[2,  7000] loss: 1.652466561.099497795105[2,  7500] loss: 1.602097575.5820195674896[2,  8000] loss: 1.625256589.9432060718536[2,  8500] loss: 1.564624604.3094782829285[2,  9000] loss: 1.583282618.6901621818542[2,  9500] loss: 1.624456633.0893108844757[2, 10000] loss: 1.516997647.3169362545013[2, 10500] loss: 1.587447661.8263611793518[2, 11000] loss: 1.566952676.2850968837738[2, 11500] loss: 1.539926690.6358554363251[2, 12000] loss: 1.531698704.9872364997864[2, 12500] loss: 1.512271719.3721022605896Epoch [2] loss: 5086159.665802[3,   500] loss: 1.552121733.7188172340393[3,  1000] loss: 1.438473748.0300178527832[3,  1500] loss: 1.486547762.4541957378387[3,  2000] loss: 1.481343776.9149348735809[3,  2500] loss: 1.495591791.2514169216156[3,  3000] loss: 1.497221805.5694534778595[3,  3500] loss: 1.486279820.0047135353088[3,  4000] loss: 1.523065834.4001135826111[3,  4500] loss: 1.421709848.7154848575592[3,  5000] loss: 1.444857863.1398198604584[3,  5500] loss: 1.558532877.5550718307495[3,  6000] loss: 1.468729891.9653513431549[3,  6500] loss: 1.456428906.7072341442108[3,  7000] loss: 1.447384920.9760098457336[3,  7500] loss: 1.393756935.3260359764099[3,  8000] loss: 1.446680949.7621910572052[3,  8500] loss: 1.376389964.1196668148041[3,  9000] loss: 1.403700978.5461337566376[3,  9500] loss: 1.423650993.0276567935944[3, 10000] loss: 1.4019091007.3188300132751[3, 10500] loss: 1.4800471021.5726852416992[3, 11000] loss: 1.3953531035.998346567154[3, 11500] loss: 1.4054661050.0993807315826[3, 12000] loss: 1.4026701064.369329214096[3, 12500] loss: 1.4138401078.65274643898Epoch [3] loss: 4547652.552931[4,   500] loss: 1.3853531093.0839562416077[4,  1000] loss: 1.3410241107.2314553260803[4,  1500] loss: 1.3690931121.426608324051[4,  2000] loss: 1.3655971135.4936563968658[4,  2500] loss: 1.3059641149.9516687393188[4,  3000] loss: 1.3592111164.2924220561981[4,  3500] loss: 1.3542481178.7666285037994[4,  4000] loss: 1.3737271193.0205602645874[4,  4500] loss: 1.3012771207.3970646858215[4,  5000] loss: 1.3576671221.629852771759[4,  5500] loss: 1.3908891236.1538808345795[4,  6000] loss: 1.3374551250.7936384677887[4,  6500] loss: 1.2946041265.2907812595367[4,  7000] loss: 1.3269501279.779188632965[4,  7500] loss: 1.3172371294.4164831638336[4,  8000] loss: 1.3056591308.8463611602783[4,  8500] loss: 1.3405181323.5144531726837[4,  9000] loss: 1.3205101337.9018988609314[4,  9500] loss: 1.3435131352.269379377365[4, 10000] loss: 1.2963271366.7039194107056[4, 10500] loss: 1.2811241381.3174459934235[4, 11000] loss: 1.2519071396.0315663814545[4, 11500] loss: 1.3072181410.5508897304535[4, 12000] loss: 1.3074711424.947428703308[4, 12500] loss: 1.3146041439.3318285942078Epoch [4] loss: 4190310.469902[5,   500] loss: 1.2705311454.0680158138275[5,  1000] loss: 1.1885951468.4328680038452[5,  1500] loss: 1.2555671482.7521922588348[5,  2000] loss: 1.2291541497.2278411388397[5,  2500] loss: 1.2809341512.053200006485[5,  3000] loss: 1.2478491526.746642112732[5,  3500] loss: 1.2902911541.1261298656464[5,  4000] loss: 1.2424411555.4966115951538[5,  4500] loss: 1.2580771569.8878045082092[5,  5000] loss: 1.2650681584.2241923809052[5,  5500] loss: 1.2538611598.9048516750336[5,  6000] loss: 1.2901751613.440761566162[5,  6500] loss: 1.2801471627.9978771209717[5,  7000] loss: 1.3058381642.782610654831[5,  7500] loss: 1.2417761657.550899028778[5,  8000] loss: 1.2498711672.5438148975372[5,  8500] loss: 1.1913451687.423514842987[5,  9000] loss: 1.2261181702.2511928081512[5,  9500] loss: 1.2209561716.9358019828796[5, 10000] loss: 1.2321481731.9129722118378[5, 10500] loss: 1.2394721746.910598039627[5, 11000] loss: 1.2577081761.867308139801[5, 11500] loss: 1.2631501776.822476387024[5, 12000] loss: 1.2571191791.3450419902802[5, 12500] loss: 1.1794821805.820249080658Epoch [5] loss: 3916791.745368Finished TrainingSaving model to /data/s4091221/trained-models/googlenet2020-02-24 20:35:40.411541GroundTruth:    cat  ship  ship planeSending data to GPUSending model to GPUtensor([[ 6.5321e+00,  7.6079e+00,  6.9252e+00,  ..., -2.6043e-01,         -2.3909e-01,  5.0334e-02],        [ 1.2365e+01,  1.4784e+01,  1.1166e+01,  ...,  4.6794e-01,          8.8561e-01, -2.3393e-02],        [ 2.0902e+01,  3.7068e+01,  2.2229e+01,  ..., -8.7613e+00,         -6.5871e+00, -4.1122e+00],        [ 1.4736e+01,  9.4368e+00,  1.0057e+01,  ...,  4.3222e-01,         -1.3076e+00, -9.2381e-01]], device='cuda:0', grad_fn=<AddmmBackward>)Predicted:    cat  ship truck planeAccuracy of the network on the 4000.0 test images: 64 %###########################################################################################################{'use_cuda': True, 'peregrine': True, 'include_visuals': False, 'normalise': False, 'load_from_memory': False, 'pretrain': True, 'batch_size': 4, 'workers': 2, 'model_archi': 15, 'trainset_size': 20000, 'epochs': 5, 'learning_rate': 0.001, 'momentum': 0, 'weight_decay': 0, 'optimizer_choice': 1}Namespace(batch_size=4, epochs=5, include_visuals=False, learning_rate=0.001, load_from_memory=False, model_archi=15, momentum=0, normalise=False, optimizer_choice=1, peregrine=True, pretrain=True, trainset_size=20000, use_cuda=True, weight_decay=0, workers=2)Files already downloaded and verifiedFiles already downloaded and verifiedcuda:012500truck truck  deer  ship['alexnet', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'googlenet', 'inception_v3', 'mnasnet0_5', 'mnasnet0_75', 'mnasnet1_0', 'mnasnet1_3', 'mobilenet_v2', 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50', 'resnext101_32x8d', 'resnext50_32x4d', 'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0', 'shufflenet_v2_x1_5', 'shufflenet_v2_x2_0', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'wide_resnet101_2', 'wide_resnet50_2']Model resnet34 LoadedResNet(  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)  (relu): ReLU(inplace=True)  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)  (layer1): Sequential(    (0): BasicBlock(      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (relu): ReLU(inplace=True)      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    )    (1): BasicBlock(      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (relu): ReLU(inplace=True)      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    )    (2): BasicBlock(      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (relu): ReLU(inplace=True)      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    )  )  (layer2): Sequential(    (0): BasicBlock(      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (relu): ReLU(inplace=True)      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (downsample): Sequential(        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      )    )    (1): BasicBlock(      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (relu): ReLU(inplace=True)      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    )    (2): BasicBlock(      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (relu): ReLU(inplace=True)      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    )    (3): BasicBlock(      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (relu): ReLU(inplace=True)      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    )  )  (layer3): Sequential(    (0): BasicBlock(      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (relu): ReLU(inplace=True)      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (downsample): Sequential(        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      )    )    (1): BasicBlock(      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (relu): ReLU(inplace=True)      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    )    (2): BasicBlock(      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (relu): ReLU(inplace=True)      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    )    (3): BasicBlock(      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (relu): ReLU(inplace=True)      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    )    (4): BasicBlock(      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (relu): ReLU(inplace=True)      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    )    (5): BasicBlock(      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (relu): ReLU(inplace=True)      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    )  )  (layer4): Sequential(    (0): BasicBlock(      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (relu): ReLU(inplace=True)      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (downsample): Sequential(        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      )    )    (1): BasicBlock(      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (relu): ReLU(inplace=True)      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    )    (2): BasicBlock(      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (relu): ReLU(inplace=True)      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    )  )  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))  (fc): Linear(in_features=512, out_features=10, bias=True))Model resnet34 ReshapedSending model to GPULearning Rate: 0.001, Weight Decay: 0, Momentum: 0Defined <class 'torch.optim.sgd.SGD'> OptimizerStarting Training at 1582572974.6108327[1,   500] loss: 2.2053958.852469205856323[1,  1000] loss: 2.05755217.64035439491272[1,  1500] loss: 2.00788326.513325929641724[1,  2000] loss: 1.91068035.31471371650696[1,  2500] loss: 1.86155444.08396315574646[1,  3000] loss: 1.87089153.240527391433716[1,  3500] loss: 1.79014461.97285771369934[1,  4000] loss: 1.76058370.82571816444397[1,  4500] loss: 1.77612079.64673638343811[1,  5000] loss: 1.69791388.3948585987091[1,  5500] loss: 1.68747697.11085939407349[1,  6000] loss: 1.631182105.94267797470093[1,  6500] loss: 1.658721114.71623754501343[1,  7000] loss: 1.589029123.47628545761108[1,  7500] loss: 1.571396132.36047506332397[1,  8000] loss: 1.582271141.1221215724945[1,  8500] loss: 1.543429149.99128103256226[1,  9000] loss: 1.495594158.80654621124268[1,  9500] loss: 1.538519167.52361869812012[1, 10000] loss: 1.476588176.57585191726685[1, 10500] loss: 1.503244185.36380410194397[1, 11000] loss: 1.466310194.07808756828308[1, 11500] loss: 1.439974202.89760899543762[1, 12000] loss: 1.428059211.6486849784851[1, 12500] loss: 1.345821220.26608562469482Epoch [1] loss: 5273521.773817[2,   500] loss: 1.445390228.9689645767212[2,  1000] loss: 1.355998237.7606325149536[2,  1500] loss: 1.334215246.39576625823975[2,  2000] loss: 1.351856255.05805087089539[2,  2500] loss: 1.359375263.73649549484253[2,  3000] loss: 1.342248272.4709746837616[2,  3500] loss: 1.329692281.0289189815521[2,  4000] loss: 1.327271289.69951248168945[2,  4500] loss: 1.326450298.57250690460205[2,  5000] loss: 1.331821307.3211750984192[2,  5500] loss: 1.287381315.9018626213074[2,  6000] loss: 1.231944324.6151669025421[2,  6500] loss: 1.320538333.2696316242218[2,  7000] loss: 1.286048341.99688053131104[2,  7500] loss: 1.240103350.76652550697327[2,  8000] loss: 1.234189359.5317192077637[2,  8500] loss: 1.246961368.2732639312744[2,  9000] loss: 1.196082377.0086567401886[2,  9500] loss: 1.196226385.7962920665741[2, 10000] loss: 1.196162394.4865310192108[2, 10500] loss: 1.212734403.11512756347656[2, 11000] loss: 1.162246411.75921511650085[2, 11500] loss: 1.199392420.8530521392822[2, 12000] loss: 1.189469429.60564041137695[2, 12500] loss: 1.176953438.25539231300354Epoch [2] loss: 3997854.657235[3,   500] loss: 1.134308447.1457085609436[3,  1000] loss: 1.108356455.8800518512726[3,  1500] loss: 1.212785464.75809931755066[3,  2000] loss: 1.095442473.59070324897766[3,  2500] loss: 1.111563482.37491369247437[3,  3000] loss: 1.151040491.1404564380646[3,  3500] loss: 1.090908499.93247628211975[3,  4000] loss: 1.081113508.79242396354675[3,  4500] loss: 1.114017517.6392934322357[3,  5000] loss: 1.139176526.4249422550201[3,  5500] loss: 1.056525535.3513102531433[3,  6000] loss: 1.110454544.4245553016663[3,  6500] loss: 1.066343553.2663421630859[3,  7000] loss: 1.108902562.0385911464691[3,  7500] loss: 1.057573570.9252223968506[3,  8000] loss: 1.038870579.6433601379395[3,  8500] loss: 1.042366588.4603836536407[3,  9000] loss: 1.123037597.2367234230042[3,  9500] loss: 1.042146605.9649176597595[3, 10000] loss: 1.067444614.6597011089325[3, 10500] loss: 1.055282623.5067241191864[3, 11000] loss: 1.124322632.203556060791[3, 11500] loss: 1.051843640.892168045044[3, 12000] loss: 0.999689649.6063718795776[3, 12500] loss: 1.015560658.3525002002716Epoch [3] loss: 3393745.425728[4,   500] loss: 0.954733667.3288042545319[4,  1000] loss: 0.980791676.03044962883[4,  1500] loss: 1.013431684.7670993804932[4,  2000] loss: 1.030104693.531895160675[4,  2500] loss: 1.025826702.2173628807068[4,  3000] loss: 1.074100710.9249823093414[4,  3500] loss: 0.999979719.6993162631989[4,  4000] loss: 0.977246728.5110805034637[4,  4500] loss: 0.962080737.2478179931641[4,  5000] loss: 0.972480745.9266893863678[4,  5500] loss: 0.978190754.5682442188263[4,  6000] loss: 0.946749763.3390355110168[4,  6500] loss: 0.983517772.1732451915741[4,  7000] loss: 1.000552780.8941512107849[4,  7500] loss: 0.925731789.6744227409363[4,  8000] loss: 0.983171798.3485906124115[4,  8500] loss: 0.983605807.0354571342468[4,  9000] loss: 0.994752815.8462765216827[4,  9500] loss: 0.960697824.5369715690613[4, 10000] loss: 0.956900833.3240942955017[4, 10500] loss: 0.922440842.2503986358643[4, 11000] loss: 0.917855851.0488166809082[4, 11500] loss: 0.964122859.9867560863495[4, 12000] loss: 0.976922868.6998553276062[4, 12500] loss: 0.949265877.4238502979279Epoch [4] loss: 3066492.605096[5,   500] loss: 0.909513886.1778008937836[5,  1000] loss: 0.886426894.9826383590698[5,  1500] loss: 0.941357903.7216069698334[5,  2000] loss: 0.876318912.7144792079926[5,  2500] loss: 0.865260921.5325870513916[5,  3000] loss: 0.895767930.3061671257019[5,  3500] loss: 0.856946938.979686498642[5,  4000] loss: 0.866258947.6887888908386[5,  4500] loss: 0.870279956.4524011611938[5,  5000] loss: 0.846147965.2187733650208[5,  5500] loss: 0.845652973.9308338165283[5,  6000] loss: 0.839588982.7470242977142[5,  6500] loss: 0.839890991.5111401081085[5,  7000] loss: 0.8311231000.2272176742554[5,  7500] loss: 0.8560081008.9131259918213[5,  8000] loss: 0.8540711017.8337495326996[5,  8500] loss: 0.9208071026.598301410675[5,  9000] loss: 0.9279831035.7008774280548[5,  9500] loss: 0.8756691044.4626779556274[5, 10000] loss: 0.8866591053.2985689640045[5, 10500] loss: 0.8870171061.940102338791[5, 11000] loss: 0.8739411070.6025774478912[5, 11500] loss: 0.8510781079.393991470337[5, 12000] loss: 0.8728001088.0798168182373[5, 12500] loss: 0.8382911096.7397332191467Epoch [5] loss: 2719157.436677Finished TrainingSaving model to /data/s4091221/trained-models/resnet342020-02-24 20:54:31.385375GroundTruth:    cat  ship  ship planeSending data to GPUSending model to GPUtensor([[-8.8697e+00,  6.3897e-01,  5.2682e-01,  1.0389e+01, -4.7819e+00,          2.8893e+00, -8.2583e-01, -3.4740e+00,  1.2317e+00,  2.0738e+00],        [ 4.7772e+00,  1.1854e+01, -1.3677e+00, -3.0727e+00, -7.5464e+00,         -7.1312e+00, -1.0043e+01, -8.0443e+00,  1.3559e+01,  2.4952e+00],        [ 7.7279e-01,  9.2730e-01, -1.4260e+00,  1.4977e-01, -1.7214e+00,         -1.6838e+00, -4.5610e-01, -2.0311e+00,  1.1289e+00,  1.1416e+00],        [ 1.4663e+00, -1.3701e-01, -3.8582e-01, -1.6478e-01, -7.3565e-01,         -9.7304e-01, -2.7408e-01, -1.1588e+00, -3.4832e-03, -4.0658e-01]],       device='cuda:0', grad_fn=<AddmmBackward>)Predicted:    cat  ship truck planeAccuracy of the network on the 4000.0 test images: 75 %###########################################################################################################{'use_cuda': True, 'peregrine': True, 'include_visuals': False, 'normalise': False, 'load_from_memory': False, 'pretrain': True, 'batch_size': 4, 'workers': 2, 'model_archi': 25, 'trainset_size': 20000, 'epochs': 5, 'learning_rate': 0.001, 'momentum': 0, 'weight_decay': 0, 'optimizer_choice': 1}Namespace(batch_size=4, epochs=5, include_visuals=False, learning_rate=0.001, load_from_memory=False, model_archi=25, momentum=0, normalise=False, optimizer_choice=1, peregrine=True, pretrain=True, trainset_size=20000, use_cuda=True, weight_decay=0, workers=2)Files already downloaded and verifiedFiles already downloaded and verifiedcuda:012500 frog  deer   dog   car['alexnet', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'googlenet', 'inception_v3', 'mnasnet0_5', 'mnasnet0_75', 'mnasnet1_0', 'mnasnet1_3', 'mobilenet_v2', 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50', 'resnext101_32x8d', 'resnext50_32x4d', 'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0', 'shufflenet_v2_x1_5', 'shufflenet_v2_x2_0', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'wide_resnet101_2', 'wide_resnet50_2']Model vgg11 LoadedVGG(  (features): Sequential(    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (1): ReLU(inplace=True)    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (4): ReLU(inplace=True)    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (7): ReLU(inplace=True)    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (9): ReLU(inplace=True)    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (12): ReLU(inplace=True)    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (14): ReLU(inplace=True)    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (17): ReLU(inplace=True)    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (19): ReLU(inplace=True)    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  )  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))  (classifier): Sequential(    (0): Linear(in_features=25088, out_features=4096, bias=True)    (1): ReLU(inplace=True)    (2): Dropout(p=0.5, inplace=False)    (3): Linear(in_features=4096, out_features=4096, bias=True)    (4): ReLU(inplace=True)    (5): Dropout(p=0.5, inplace=False)    (6): Linear(in_features=4096, out_features=10, bias=True)  ))Model vgg11 ReshapedSending model to GPULearning Rate: 0.001, Weight Decay: 0, Momentum: 0Defined <class 'torch.optim.sgd.SGD'> OptimizerStarting Training at 1582574097.6067312[1,   500] loss: 1.7118465.067424535751343[1,  1000] loss: 1.33272110.025137662887573[1,  1500] loss: 1.09116414.969281673431396[1,  2000] loss: 1.05437019.928993225097656[1,  2500] loss: 0.93735624.872800588607788[1,  3000] loss: 0.92040129.828637838363647[1,  3500] loss: 0.89157834.82237362861633[1,  4000] loss: 0.83222439.78022885322571[1,  4500] loss: 0.83514844.73549485206604[1,  5000] loss: 0.77513949.68343162536621[1,  5500] loss: 0.76266954.642884731292725[1,  6000] loss: 0.73255259.576258420944214[1,  6500] loss: 0.74885064.50836443901062[1,  7000] loss: 0.72241069.43583726882935[1,  7500] loss: 0.74843074.39661145210266[1,  8000] loss: 0.66158179.38545775413513[1,  8500] loss: 0.69023584.32527422904968[1,  9000] loss: 0.71461389.29370093345642[1,  9500] loss: 0.66378094.24278569221497[1, 10000] loss: 0.64874699.18155646324158[1, 10500] loss: 0.673561104.10737562179565[1, 11000] loss: 0.675523109.07830262184143[1, 11500] loss: 0.615615114.02611351013184[1, 12000] loss: 0.645795118.96665382385254[1, 12500] loss: 0.596888123.90109181404114Epoch [1] loss: 2612302.977283[2,   500] loss: 0.502396128.940833568573[2,  1000] loss: 0.502969133.87663888931274[2,  1500] loss: 0.507730138.83844900131226[2,  2000] loss: 0.508724143.7911777496338[2,  2500] loss: 0.503663148.71692323684692[2,  3000] loss: 0.515196153.64934611320496[2,  3500] loss: 0.504027158.62435483932495[2,  4000] loss: 0.530417163.56014466285706[2,  4500] loss: 0.530134168.51406693458557[2,  5000] loss: 0.493388173.44800233840942[2,  5500] loss: 0.537953178.38286232948303[2,  6000] loss: 0.533266183.32437682151794[2,  6500] loss: 0.510911188.27428913116455[2,  7000] loss: 0.453761193.22585439682007[2,  7500] loss: 0.526199198.19585180282593[2,  8000] loss: 0.479040203.1496262550354[2,  8500] loss: 0.486023208.08491396903992[2,  9000] loss: 0.486323213.04423260688782[2,  9500] loss: 0.498422217.99013209342957[2, 10000] loss: 0.479538222.9290030002594[2, 10500] loss: 0.509396227.86324644088745[2, 11000] loss: 0.522138232.8117871284485[2, 11500] loss: 0.474585237.75787091255188[2, 12000] loss: 0.465408242.68802905082703[2, 12500] loss: 0.468826247.64635300636292Epoch [2] loss: 1567013.829598[3,   500] loss: 0.358552252.711421251297[3,  1000] loss: 0.376373257.6782214641571[3,  1500] loss: 0.374073262.6281180381775[3,  2000] loss: 0.350076267.58813762664795[3,  2500] loss: 0.393401272.53355383872986[3,  3000] loss: 0.354973277.48076248168945[3,  3500] loss: 0.391052282.46698689460754[3,  4000] loss: 0.359392287.41850304603577[3,  4500] loss: 0.356058292.37294936180115[3,  5000] loss: 0.339060297.30582094192505[3,  5500] loss: 0.355647302.26052069664[3,  6000] loss: 0.386401307.2617871761322[3,  6500] loss: 0.368640312.23240756988525[3,  7000] loss: 0.396312317.2011008262634[3,  7500] loss: 0.351617322.1788430213928[3,  8000] loss: 0.365198327.1524279117584[3,  8500] loss: 0.362415332.0918619632721[3,  9000] loss: 0.386984337.05445671081543[3,  9500] loss: 0.371560341.99544405937195[3, 10000] loss: 0.352576346.9347994327545[3, 10500] loss: 0.360918351.87618494033813[3, 11000] loss: 0.316520356.8104224205017[3, 11500] loss: 0.346497361.74893856048584[3, 12000] loss: 0.325569366.6990122795105[3, 12500] loss: 0.390608371.640248298645Epoch [3] loss: 1134878.741448[4,   500] loss: 0.238015376.6894772052765[4,  1000] loss: 0.265286381.62640023231506[4,  1500] loss: 0.261928386.561794757843[4,  2000] loss: 0.232469391.5127363204956[4,  2500] loss: 0.234119396.45387601852417[4,  3000] loss: 0.287424401.39780950546265[4,  3500] loss: 0.283515406.40951561927795[4,  4000] loss: 0.251142411.35077714920044[4,  4500] loss: 0.266455416.2967755794525[4,  5000] loss: 0.310002421.2367355823517[4,  5500] loss: 0.256351426.1893937587738[4,  6000] loss: 0.275769431.1232671737671[4,  6500] loss: 0.270293436.0483365058899[4,  7000] loss: 0.255952440.99937868118286[4,  7500] loss: 0.264683445.9292514324188[4,  8000] loss: 0.261527450.87995195388794[4,  8500] loss: 0.266676455.8166379928589[4,  9000] loss: 0.259753460.7708375453949[4,  9500] loss: 0.248292465.7058379650116[4, 10000] loss: 0.290782470.641077041626[4, 10500] loss: 0.267711475.5664234161377[4, 11000] loss: 0.256256480.49947214126587[4, 11500] loss: 0.276492485.4491512775421[4, 12000] loss: 0.285626490.38002252578735[4, 12500] loss: 0.285981495.33513283729553Epoch [4] loss: 844678.084058[5,   500] loss: 0.173301500.4195032119751[5,  1000] loss: 0.202781505.3771529197693[5,  1500] loss: 0.159973510.32577443122864[5,  2000] loss: 0.159876515.2662155628204[5,  2500] loss: 0.175128520.2131650447845[5,  3000] loss: 0.191663525.1399531364441[5,  3500] loss: 0.167543530.1372447013855[5,  4000] loss: 0.203675535.0690448284149[5,  4500] loss: 0.176949540.0105729103088[5,  5000] loss: 0.177565544.9351508617401[5,  5500] loss: 0.190837549.8600687980652[5,  6000] loss: 0.185555554.7908782958984[5,  6500] loss: 0.189499559.7391998767853[5,  7000] loss: 0.176617564.6707966327667[5,  7500] loss: 0.197424569.5983004570007[5,  8000] loss: 0.218868574.5506200790405[5,  8500] loss: 0.205736579.4997322559357[5,  9000] loss: 0.196771584.4451234340668[5,  9500] loss: 0.200532589.4015915393829[5, 10000] loss: 0.203137594.3406858444214[5, 10500] loss: 0.180447599.2965667247772[5, 11000] loss: 0.205581604.2326853275299[5, 11500] loss: 0.203061609.2120387554169[5, 12000] loss: 0.175505614.154224395752[5, 12500] loss: 0.206718619.1130602359772Epoch [5] loss: 589625.403904Finished TrainingSaving model to /data/s4091221/trained-models/vgg112020-02-24 21:05:16.755584GroundTruth:    cat  ship  ship planeSending data to GPUSending model to GPUtensor([[-2.2264,  0.4952, -1.8588,  7.7720, -3.4971,  4.6021, -1.5566, -1.5265,         -3.1983,  1.1417],        [ 1.8998,  6.5453, -2.3363, -2.8516, -2.5368, -2.9184, -2.4024, -3.2816,          5.0684,  1.3640],        [ 2.6770,  7.5469, -2.5493, -2.7843, -2.3415, -3.1299, -2.4835, -2.1944,          2.8384,  0.9470],        [ 4.4340,  5.5364, -2.1370, -1.6318, -3.2919, -3.2514, -1.5304, -3.5999,          3.1341,  2.0626]], device='cuda:0', grad_fn=<AddmmBackward>)Predicted:    cat   car   car   carAccuracy of the network on the 4000.0 test images: 84 %###########################################################################################################{'use_cuda': True, 'peregrine': True, 'include_visuals': False, 'normalise': False, 'load_from_memory': False, 'pretrain': True, 'batch_size': 4, 'workers': 2, 'model_archi': 26, 'trainset_size': 20000, 'epochs': 5, 'learning_rate': 0.001, 'momentum': 0, 'weight_decay': 0, 'optimizer_choice': 1}Namespace(batch_size=4, epochs=5, include_visuals=False, learning_rate=0.001, load_from_memory=False, model_archi=26, momentum=0, normalise=False, optimizer_choice=1, peregrine=True, pretrain=True, trainset_size=20000, use_cuda=True, weight_decay=0, workers=2)Files already downloaded and verifiedFiles already downloaded and verifiedcuda:012500 deer truck  ship   car['alexnet', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'googlenet', 'inception_v3', 'mnasnet0_5', 'mnasnet0_75', 'mnasnet1_0', 'mnasnet1_3', 'mobilenet_v2', 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50', 'resnext101_32x8d', 'resnext50_32x4d', 'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0', 'shufflenet_v2_x1_5', 'shufflenet_v2_x2_0', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'wide_resnet101_2', 'wide_resnet50_2']Model vgg11_bn LoadedVGG(  (features): Sequential(    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    (2): ReLU(inplace=True)    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    (6): ReLU(inplace=True)    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    (10): ReLU(inplace=True)    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    (13): ReLU(inplace=True)    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    (17): ReLU(inplace=True)    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    (20): ReLU(inplace=True)    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    (24): ReLU(inplace=True)    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    (27): ReLU(inplace=True)    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  )  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))  (classifier): Sequential(    (0): Linear(in_features=25088, out_features=4096, bias=True)    (1): ReLU(inplace=True)    (2): Dropout(p=0.5, inplace=False)    (3): Linear(in_features=4096, out_features=4096, bias=True)    (4): ReLU(inplace=True)    (5): Dropout(p=0.5, inplace=False)    (6): Linear(in_features=4096, out_features=10, bias=True)  ))Model vgg11_bn ReshapedSending model to GPULearning Rate: 0.001, Weight Decay: 0, Momentum: 0Defined <class 'torch.optim.sgd.SGD'> OptimizerStarting Training at 1582574735.7558334[1,   500] loss: 2.0838445.507211446762085[1,  1000] loss: 1.70054010.924010515213013[1,  1500] loss: 1.47268316.40943717956543[1,  2000] loss: 1.42093721.79952907562256[1,  2500] loss: 1.41457727.218341588974[1,  3000] loss: 1.35918432.660341024398804[1,  3500] loss: 1.22958138.100502252578735[1,  4000] loss: 1.23102643.51824355125427[1,  4500] loss: 1.18014948.900628089904785[1,  5000] loss: 1.13692954.283602714538574[1,  5500] loss: 1.05919259.71614122390747[1,  6000] loss: 1.07342365.19671940803528[1,  6500] loss: 1.08632970.62054872512817[1,  7000] loss: 1.01884476.05637288093567[1,  7500] loss: 1.05023781.47943997383118[1,  8000] loss: 0.95998486.92620635032654[1,  8500] loss: 0.97000792.40100145339966[1,  9000] loss: 0.95072197.81563949584961[1,  9500] loss: 0.962846103.28243637084961[1, 10000] loss: 0.961407108.6960859298706[1, 10500] loss: 0.929907114.11957383155823[1, 11000] loss: 0.923660119.59333777427673[1, 11500] loss: 0.849185125.08532166481018[1, 12000] loss: 0.889856130.55126953125[1, 12500] loss: 0.899318136.07391166687012Epoch [1] loss: 3649057.698298[2,   500] loss: 0.801066141.6368227005005[2,  1000] loss: 0.824437147.05413913726807[2,  1500] loss: 0.733085152.4744691848755[2,  2000] loss: 0.773759157.89867854118347[2,  2500] loss: 0.800640163.3838667869568[2,  3000] loss: 0.763308168.78850173950195[2,  3500] loss: 0.740195174.22019481658936[2,  4000] loss: 0.759043179.65748119354248[2,  4500] loss: 0.769972185.0544867515564[2,  5000] loss: 0.787411190.44151639938354[2,  5500] loss: 0.762711195.88662004470825[2,  6000] loss: 0.753627201.2833080291748[2,  6500] loss: 0.744792206.69764804840088[2,  7000] loss: 0.715811212.1693880558014[2,  7500] loss: 0.693089217.600980758667[2,  8000] loss: 0.718003223.02875781059265[2,  8500] loss: 0.695285228.42420077323914[2,  9000] loss: 0.685542233.84405374526978[2,  9500] loss: 0.702134239.30455350875854[2, 10000] loss: 0.687019244.74019122123718[2, 10500] loss: 0.705261250.17356991767883[2, 11000] loss: 0.674434255.58204555511475[2, 11500] loss: 0.647609261.0248649120331[2, 12000] loss: 0.650390266.42574310302734[2, 12500] loss: 0.673615271.83199739456177Epoch [2] loss: 2295558.172987[3,   500] loss: 0.616005277.40970158576965[3,  1000] loss: 0.592706282.8272466659546[3,  1500] loss: 0.580775288.2333142757416[3,  2000] loss: 0.575603293.6330428123474[3,  2500] loss: 0.582985299.05703353881836[3,  3000] loss: 0.610895304.45986890792847[3,  3500] loss: 0.596852309.837486743927[3,  4000] loss: 0.552421315.2462320327759[3,  4500] loss: 0.592073320.63530588150024[3,  5000] loss: 0.570112326.0560336112976[3,  5500] loss: 0.566241331.4413592815399[3,  6000] loss: 0.564686336.8427517414093[3,  6500] loss: 0.543062342.2739989757538[3,  7000] loss: 0.555473347.70542573928833[3,  7500] loss: 0.596139353.1285779476166[3,  8000] loss: 0.563941358.5857398509979[3,  8500] loss: 0.598312364.02741169929504[3,  9000] loss: 0.575268369.4584629535675[3,  9500] loss: 0.555136374.8775329589844[3, 10000] loss: 0.559030380.25971817970276[3, 10500] loss: 0.537474385.76295733451843[3, 11000] loss: 0.561295391.20417523384094[3, 11500] loss: 0.524793396.6548674106598[3, 12000] loss: 0.537345402.1012432575226[3, 12500] loss: 0.537689407.5274500846863Epoch [3] loss: 1785885.174671[4,   500] loss: 0.464128413.0815854072571[4,  1000] loss: 0.482538418.5024538040161[4,  1500] loss: 0.447186423.9746220111847[4,  2000] loss: 0.433495429.40785694122314[4,  2500] loss: 0.457710434.8258686065674[4,  3000] loss: 0.462880440.2041826248169[4,  3500] loss: 0.491712445.6438035964966[4,  4000] loss: 0.503486451.0600287914276[4,  4500] loss: 0.474696456.50958776474[4,  5000] loss: 0.451600461.9604640007019[4,  5500] loss: 0.497544467.3822295665741[4,  6000] loss: 0.479191472.76946806907654[4,  6500] loss: 0.451113478.231725692749[4,  7000] loss: 0.465807483.669606924057[4,  7500] loss: 0.429126489.043664932251[4,  8000] loss: 0.467487494.4399802684784[4,  8500] loss: 0.451829499.8328449726105[4,  9000] loss: 0.493545505.28296279907227[4,  9500] loss: 0.420076510.7353687286377[4, 10000] loss: 0.460360516.2165412902832[4, 10500] loss: 0.462788521.6618840694427[4, 11000] loss: 0.462689527.1052310466766[4, 11500] loss: 0.441740532.4884901046753[4, 12000] loss: 0.437617537.8860824108124[4, 12500] loss: 0.435181543.3065783977509Epoch [4] loss: 1439001.970849[5,   500] loss: 0.382288548.8646945953369[5,  1000] loss: 0.343921554.2772703170776[5,  1500] loss: 0.379303559.7831118106842[5,  2000] loss: 0.344176565.1918637752533[5,  2500] loss: 0.381407570.6081969738007[5,  3000] loss: 0.396000575.9887132644653[5,  3500] loss: 0.336903581.4087994098663[5,  4000] loss: 0.369448586.8538408279419[5,  4500] loss: 0.377782592.2730093002319[5,  5000] loss: 0.381600597.6590676307678[5,  5500] loss: 0.370478603.0497210025787[5,  6000] loss: 0.366385608.4106454849243[5,  6500] loss: 0.390522613.7885510921478[5,  7000] loss: 0.385300619.1977872848511[5,  7500] loss: 0.379239624.6067769527435[5,  8000] loss: 0.369727630.1159377098083[5,  8500] loss: 0.384334635.574844121933[5,  9000] loss: 0.407712640.9955558776855[5,  9500] loss: 0.368364646.4121971130371[5, 10000] loss: 0.388991651.8648931980133[5, 10500] loss: 0.386502657.2707080841064[5, 11000] loss: 0.384270662.7258763313293[5, 11500] loss: 0.366611668.1206035614014[5, 12000] loss: 0.384205673.5553090572357[5, 12500] loss: 0.365336678.964209318161Epoch [5] loss: 1170931.336313Finished TrainingSaving model to /data/s4091221/trained-models/vgg11_bn2020-02-24 21:16:54.754071GroundTruth:    cat  ship  ship planeSending data to GPUSending model to GPUtensor([[-2.3951e+00, -3.4452e+00,  2.2903e+00,  8.3524e+00, -3.1442e+00,          6.6759e+00,  4.3363e-01, -1.0623e+00, -4.0202e+00, -4.0964e+00],        [ 1.2274e+00,  4.8028e+00, -2.4698e+00, -1.0343e-03, -4.2846e+00,         -1.6275e+00, -2.8344e+00, -2.5420e+00,  8.2556e+00, -5.0794e-01],        [ 3.4461e+00,  2.6405e+00, -1.4296e+00, -2.5989e+00, -8.3360e-01,         -3.3594e+00, -3.3917e+00, -1.5075e+00,  5.7350e+00,  2.4487e-01],        [ 5.3788e+00,  7.2693e-01,  2.3279e-02,  2.0194e-01, -2.5140e+00,         -1.7896e+00, -2.0039e+00, -2.0008e+00,  1.5966e+00, -1.9540e-01]],       device='cuda:0', grad_fn=<AddmmBackward>)Predicted:    cat  ship  ship planeAccuracy of the network on the 4000.0 test images: 84 %###########################################################################################################{'use_cuda': True, 'peregrine': True, 'include_visuals': False, 'normalise': False, 'load_from_memory': False, 'pretrain': True, 'batch_size': 4, 'workers': 2, 'model_archi': 31, 'trainset_size': 20000, 'epochs': 5, 'learning_rate': 0.001, 'momentum': 0, 'weight_decay': 0, 'optimizer_choice': 1}Namespace(batch_size=4, epochs=5, include_visuals=False, learning_rate=0.001, load_from_memory=False, model_archi=31, momentum=0, normalise=False, optimizer_choice=1, peregrine=True, pretrain=True, trainset_size=20000, use_cuda=True, weight_decay=0, workers=2)Files already downloaded and verifiedFiles already downloaded and verifiedcuda:0Downloading: "https://download.pytorch.org/models/vgg19-dcbb9e9d.pth" to /home/s4091221/.cache/torch/checkpoints/vgg19-dcbb9e9d.pth12500 ship truck   dog truck['alexnet', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'googlenet', 'inception_v3', 'mnasnet0_5', 'mnasnet0_75', 'mnasnet1_0', 'mnasnet1_3', 'mobilenet_v2', 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50', 'resnext101_32x8d', 'resnext50_32x4d', 'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0', 'shufflenet_v2_x1_5', 'shufflenet_v2_x2_0', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'wide_resnet101_2', 'wide_resnet50_2']Model vgg19 LoadedVGG(  (features): Sequential(    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (1): ReLU(inplace=True)    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (3): ReLU(inplace=True)    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (6): ReLU(inplace=True)    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (8): ReLU(inplace=True)    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (11): ReLU(inplace=True)    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (13): ReLU(inplace=True)    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (15): ReLU(inplace=True)    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (17): ReLU(inplace=True)    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (20): ReLU(inplace=True)    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (22): ReLU(inplace=True)    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (24): ReLU(inplace=True)    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (26): ReLU(inplace=True)    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (29): ReLU(inplace=True)    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (31): ReLU(inplace=True)    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (33): ReLU(inplace=True)    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (35): ReLU(inplace=True)    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  )  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))  (classifier): Sequential(    (0): Linear(in_features=25088, out_features=4096, bias=True)    (1): ReLU(inplace=True)    (2): Dropout(p=0.5, inplace=False)    (3): Linear(in_features=4096, out_features=4096, bias=True)    (4): ReLU(inplace=True)    (5): Dropout(p=0.5, inplace=False)    (6): Linear(in_features=4096, out_features=10, bias=True)  ))Model vgg19 ReshapedSending model to GPULearning Rate: 0.001, Weight Decay: 0, Momentum: 0Defined <class 'torch.optim.sgd.SGD'> OptimizerStarting Training at 1582575454.4784873[1,   500] loss: 1.6878416.491468191146851[1,  1000] loss: 1.11950012.860098361968994[1,  1500] loss: 0.98564619.221845626831055[1,  2000] loss: 0.87613225.57410216331482[1,  2500] loss: 0.83759431.937953233718872[1,  3000] loss: 0.74876038.3387553691864[1,  3500] loss: 0.78369844.69385886192322[1,  4000] loss: 0.73521251.0532763004303[1,  4500] loss: 0.67238957.40266704559326[1,  5000] loss: 0.65288363.74166488647461[1,  5500] loss: 0.68469770.09906673431396[1,  6000] loss: 0.64559076.47860455513[1,  6500] loss: 0.59116682.80870652198792[1,  7000] loss: 0.61452189.15655255317688[1,  7500] loss: 0.57668095.50470232963562[1,  8000] loss: 0.590041101.85854291915894[1,  8500] loss: 0.592338108.19560623168945[1,  9000] loss: 0.535472114.56780648231506[1,  9500] loss: 0.596778120.90422320365906[1, 10000] loss: 0.554644127.24412989616394[1, 10500] loss: 0.528791133.6015682220459[1, 11000] loss: 0.555330139.94536924362183[1, 11500] loss: 0.569818146.28733134269714[1, 12000] loss: 0.540642152.65985941886902[1, 12500] loss: 0.527888159.11126112937927Epoch [1] loss: 2266963.711957[2,   500] loss: 0.418072165.64262557029724[2,  1000] loss: 0.430201171.99795031547546[2,  1500] loss: 0.387729178.35071206092834[2,  2000] loss: 0.437931184.71873116493225[2,  2500] loss: 0.416646191.06831622123718[2,  3000] loss: 0.419024197.43184089660645[2,  3500] loss: 0.445064203.8016641139984[2,  4000] loss: 0.430728210.16653633117676[2,  4500] loss: 0.428324216.52744507789612[2,  5000] loss: 0.384060222.88337182998657[2,  5500] loss: 0.389952229.34535455703735[2,  6000] loss: 0.399358235.70433902740479[2,  6500] loss: 0.401813242.0451021194458[2,  7000] loss: 0.412095248.39201855659485[2,  7500] loss: 0.394365254.7297568321228[2,  8000] loss: 0.392561261.0682535171509[2,  8500] loss: 0.373262267.3997440338135[2,  9000] loss: 0.363314273.74125146865845[2,  9500] loss: 0.376905280.106014251709[2, 10000] loss: 0.387427286.49069476127625[2, 10500] loss: 0.408275292.8230471611023[2, 11000] loss: 0.361115299.15684485435486[2, 11500] loss: 0.405549305.5245575904846[2, 12000] loss: 0.398396311.8710825443268[2, 12500] loss: 0.367608318.2298502922058Epoch [2] loss: 1264547.318038[3,   500] loss: 0.264111324.7211899757385[3,  1000] loss: 0.288637331.0781509876251[3,  1500] loss: 0.286421337.4483332633972[3,  2000] loss: 0.280478343.8213279247284[3,  2500] loss: 0.280221350.215167760849[3,  3000] loss: 0.253543356.58368468284607[3,  3500] loss: 0.313324362.96421551704407[3,  4000] loss: 0.284177369.32444310188293[3,  4500] loss: 0.281770375.6795332431793[3,  5000] loss: 0.280068382.03755283355713[3,  5500] loss: 0.297433388.3928470611572[3,  6000] loss: 0.307359394.7983603477478[3,  6500] loss: 0.280102401.1414906978607[3,  7000] loss: 0.309589407.5532295703888[3,  7500] loss: 0.295564413.89999055862427[3,  8000] loss: 0.292672420.29603385925293[3,  8500] loss: 0.280888426.74538111686707[3,  9000] loss: 0.295976433.0979127883911[3,  9500] loss: 0.297424439.46371483802795[3, 10000] loss: 0.288935445.80005168914795[3, 10500] loss: 0.277404452.16863489151[3, 11000] loss: 0.282458458.5255320072174[3, 11500] loss: 0.261058464.87194204330444[3, 12000] loss: 0.267757471.21686363220215[3, 12500] loss: 0.267271477.5734968185425Epoch [3] loss: 891204.606438[4,   500] loss: 0.194846484.0833661556244[4,  1000] loss: 0.194002490.43465209007263[4,  1500] loss: 0.181647496.7931170463562[4,  2000] loss: 0.215611503.15288186073303[4,  2500] loss: 0.205816509.5146415233612[4,  3000] loss: 0.191529515.8673510551453[4,  3500] loss: 0.197656522.2598919868469[4,  4000] loss: 0.188236528.6349928379059[4,  4500] loss: 0.212788534.9835960865021[4,  5000] loss: 0.211581541.3433969020844[4,  5500] loss: 0.204105547.7009165287018[4,  6000] loss: 0.203510554.0424911975861[4,  6500] loss: 0.189914560.4187107086182[4,  7000] loss: 0.181677566.7827205657959[4,  7500] loss: 0.232406573.118264913559[4,  8000] loss: 0.217361579.4644405841827[4,  8500] loss: 0.221610585.8053994178772[4,  9000] loss: 0.210442592.1321921348572[4,  9500] loss: 0.192468598.4789817333221[4, 10000] loss: 0.199814604.8019452095032[4, 10500] loss: 0.194851611.1403396129608[4, 11000] loss: 0.210434617.4799618721008[4, 11500] loss: 0.222862623.824366569519[4, 12000] loss: 0.200955630.1630051136017[4, 12500] loss: 0.217264636.5012965202332Epoch [4] loss: 642030.569971[5,   500] loss: 0.127734642.9933381080627[5,  1000] loss: 0.128569649.3332695960999[5,  1500] loss: 0.136675655.7092032432556[5,  2000] loss: 0.140737662.0623605251312[5,  2500] loss: 0.121446668.3978755474091[5,  3000] loss: 0.112506674.7339673042297[5,  3500] loss: 0.155016681.0904126167297[5,  4000] loss: 0.131590687.4533371925354[5,  4500] loss: 0.149039693.8081376552582[5,  5000] loss: 0.134607700.1491887569427[5,  5500] loss: 0.170443706.5072264671326[5,  6000] loss: 0.148017712.8691754341125[5,  6500] loss: 0.159788719.210015296936[5,  7000] loss: 0.147566725.563325881958[5,  7500] loss: 0.148211731.9085831642151[5,  8000] loss: 0.150933738.265872001648[5,  8500] loss: 0.159911744.6132218837738[5,  9000] loss: 0.156212750.9964158535004[5,  9500] loss: 0.149397757.3465490341187[5, 10000] loss: 0.139871763.7069833278656[5, 10500] loss: 0.147682770.054853439331[5, 11000] loss: 0.175404776.4780924320221[5, 11500] loss: 0.174313782.8212807178497[5, 12000] loss: 0.140057789.1778314113617[5, 12500] loss: 0.155514795.5023288726807Epoch [5] loss: 445896.492265Finished TrainingSaving model to /data/s4091221/trained-models/vgg192020-02-24 21:30:50.042119GroundTruth:    cat  ship  ship planeSending data to GPUSending model to GPUtensor([[-1.2911, -2.9258, -1.0681,  9.3914, -2.5254,  5.6549, -0.9290, -0.4328,         -2.9611, -2.6493],        [ 2.3115,  4.0680, -1.3731, -2.1796, -2.7953, -2.7635, -2.0078, -2.7608,          8.4218, -0.2835],        [ 2.9295,  2.4465, -1.3639, -1.9745, -2.6429, -2.4038, -2.4846, -2.5203,          9.0548, -0.6456],        [ 8.4301, -1.2624,  0.2401, -1.1055, -1.7397, -2.2958, -3.3537, -1.8076,          3.9475, -0.5487]], device='cuda:0', grad_fn=<AddmmBackward>)Predicted:    cat  ship  ship planeAccuracy of the network on the 4000.0 test images: 87 %###########################################################################################################{'use_cuda': True, 'peregrine': True, 'include_visuals': False, 'normalise': False, 'load_from_memory': False, 'pretrain': True, 'batch_size': 4, 'workers': 2, 'model_archi': 32, 'trainset_size': 20000, 'epochs': 5, 'learning_rate': 0.001, 'momentum': 0, 'weight_decay': 0, 'optimizer_choice': 1}Namespace(batch_size=4, epochs=5, include_visuals=False, learning_rate=0.001, load_from_memory=False, model_archi=32, momentum=0, normalise=False, optimizer_choice=1, peregrine=True, pretrain=True, trainset_size=20000, use_cuda=True, weight_decay=0, workers=2)Files already downloaded and verifiedFiles already downloaded and verifiedcuda:0Downloading: "https://download.pytorch.org/models/vgg19_bn-c79401a0.pth" to /home/s4091221/.cache/torch/checkpoints/vgg19_bn-c79401a0.pth12500plane  ship  deer  ship['alexnet', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'googlenet', 'inception_v3', 'mnasnet0_5', 'mnasnet0_75', 'mnasnet1_0', 'mnasnet1_3', 'mobilenet_v2', 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50', 'resnext101_32x8d', 'resnext50_32x4d', 'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0', 'shufflenet_v2_x1_5', 'shufflenet_v2_x2_0', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'wide_resnet101_2', 'wide_resnet50_2']Model vgg19_bn LoadedVGG(  (features): Sequential(    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    (2): ReLU(inplace=True)    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    (5): ReLU(inplace=True)    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    (9): ReLU(inplace=True)    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    (12): ReLU(inplace=True)    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    (16): ReLU(inplace=True)    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    (19): ReLU(inplace=True)    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    (22): ReLU(inplace=True)    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    (25): ReLU(inplace=True)    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    (29): ReLU(inplace=True)    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    (32): ReLU(inplace=True)    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    (35): ReLU(inplace=True)    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    (38): ReLU(inplace=True)    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    (42): ReLU(inplace=True)    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    (45): ReLU(inplace=True)    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    (48): ReLU(inplace=True)    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)    (51): ReLU(inplace=True)    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  )  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))  (classifier): Sequential(    (0): Linear(in_features=25088, out_features=4096, bias=True)    (1): ReLU(inplace=True)    (2): Dropout(p=0.5, inplace=False)    (3): Linear(in_features=4096, out_features=4096, bias=True)    (4): ReLU(inplace=True)    (5): Dropout(p=0.5, inplace=False)    (6): Linear(in_features=4096, out_features=10, bias=True)  ))Model vgg19_bn ReshapedSending model to GPULearning Rate: 0.001, Weight Decay: 0, Momentum: 0Defined <class 'torch.optim.sgd.SGD'> OptimizerStarting Training at 1582576280.8050332[1,   500] loss: 2.1160007.443515062332153[1,  1000] loss: 1.77407414.711747884750366[1,  1500] loss: 1.63870622.04036855697632[1,  2000] loss: 1.49614529.386735439300537[1,  2500] loss: 1.53817736.760706424713135[1,  3000] loss: 1.46695344.04116344451904[1,  3500] loss: 1.40718351.423015832901[1,  4000] loss: 1.30809358.74098467826843[1,  4500] loss: 1.29204766.04917097091675[1,  5000] loss: 1.25003973.49655413627625[1,  5500] loss: 1.18788180.89271879196167[1,  6000] loss: 1.21386888.2045304775238[1,  6500] loss: 1.14270795.52896332740784[1,  7000] loss: 1.150654102.82612943649292[1,  7500] loss: 1.126399110.10414290428162[1,  8000] loss: 1.160385117.41101431846619[1,  8500] loss: 1.060621124.67949962615967[1,  9000] loss: 1.058038131.97740149497986[1,  9500] loss: 1.060442139.2721004486084[1, 10000] loss: 1.021129146.5242214202881[1, 10500] loss: 1.029592153.75559306144714[1, 11000] loss: 0.966747161.05893921852112[1, 11500] loss: 1.002385168.31792187690735[1, 12000] loss: 0.972172175.5689845085144[1, 12500] loss: 0.973541182.8520359992981Epoch [1] loss: 3962356.604408[2,   500] loss: 0.902056190.22543454170227[2,  1000] loss: 0.905775197.67735528945923[2,  1500] loss: 0.894542204.9224898815155[2,  2000] loss: 0.833743212.23959922790527[2,  2500] loss: 0.872645219.52440524101257[2,  3000] loss: 0.844433226.84831714630127[2,  3500] loss: 0.791503234.13877844810486[2,  4000] loss: 0.842565241.3478012084961[2,  4500] loss: 0.821414248.64528155326843[2,  5000] loss: 0.818311255.9368929862976[2,  5500] loss: 0.837567263.2515387535095[2,  6000] loss: 0.807470270.5210337638855[2,  6500] loss: 0.765617277.8622839450836[2,  7000] loss: 0.782336285.1592710018158[2,  7500] loss: 0.765055292.4931321144104[2,  8000] loss: 0.795950299.7555456161499[2,  8500] loss: 0.741347306.9879906177521[2,  9000] loss: 0.768416314.24781250953674[2,  9500] loss: 0.769403321.6973783969879[2, 10000] loss: 0.731423328.98358964920044[2, 10500] loss: 0.751611336.23832392692566[2, 11000] loss: 0.710354343.545147895813[2, 11500] loss: 0.722382350.7810170650482[2, 12000] loss: 0.734377358.0557141304016[2, 12500] loss: 0.758960365.3216760158539Epoch [2] loss: 2515857.139024[3,   500] loss: 0.617229372.82560873031616[3,  1000] loss: 0.664984380.13077783584595[3,  1500] loss: 0.634176387.45306754112244[3,  2000] loss: 0.608612394.757853269577[3,  2500] loss: 0.606610402.09684586524963[3,  3000] loss: 0.631371409.42783641815186[3,  3500] loss: 0.631570416.7624731063843[3,  4000] loss: 0.596377424.0819902420044[3,  4500] loss: 0.614680431.3946168422699[3,  5000] loss: 0.629548438.8474750518799[3,  5500] loss: 0.576592446.2407760620117[3,  6000] loss: 0.593309453.51446437835693[3,  6500] loss: 0.606809460.7613773345947[3,  7000] loss: 0.570275468.03189039230347[3,  7500] loss: 0.580701475.26282691955566[3,  8000] loss: 0.587101482.54579186439514[3,  8500] loss: 0.619321489.82051038742065[3,  9000] loss: 0.612358497.09930086135864[3,  9500] loss: 0.600216504.3635239601135[3, 10000] loss: 0.560043511.6284649372101[3, 10500] loss: 0.601178518.8790202140808[3, 11000] loss: 0.583394526.1555068492889[3, 11500] loss: 0.560036533.469131231308[3, 12000] loss: 0.578449540.7493300437927[3, 12500] loss: 0.597613548.030923128128Epoch [3] loss: 1893903.785489[4,   500] loss: 0.517595555.4267716407776[4,  1000] loss: 0.494783562.7133693695068[4,  1500] loss: 0.485980569.9934575557709[4,  2000] loss: 0.506760577.2530326843262[4,  2500] loss: 0.535326584.5347282886505[4,  3000] loss: 0.496736591.831268787384[4,  3500] loss: 0.496085599.4248549938202[4,  4000] loss: 0.504916606.776709318161[4,  4500] loss: 0.478686614.0343034267426[4,  5000] loss: 0.502648621.3449003696442[4,  5500] loss: 0.503232628.6821994781494[4,  6000] loss: 0.455421635.9641127586365[4,  6500] loss: 0.474013643.3883759975433[4,  7000] loss: 0.470744650.6565480232239[4,  7500] loss: 0.555909657.9790380001068[4,  8000] loss: 0.510098665.2653014659882[4,  8500] loss: 0.476096672.56614112854[4,  9000] loss: 0.477845679.9499318599701[4,  9500] loss: 0.481560687.3166787624359[4, 10000] loss: 0.443916694.6968035697937[4, 10500] loss: 0.443528702.009477853775[4, 11000] loss: 0.489866709.3111324310303[4, 11500] loss: 0.497705716.6465668678284[4, 12000] loss: 0.496698723.9036247730255[4, 12500] loss: 0.461751731.2462146282196Epoch [4] loss: 1531631.112532[5,   500] loss: 0.406756741.1619935035706[5,  1000] loss: 0.422161748.4767272472382[5,  1500] loss: 0.421488755.8624715805054[5,  2000] loss: 0.430630763.1849796772003[5,  2500] loss: 0.427341770.4609014987946[5,  3000] loss: 0.397132777.755140542984[5,  3500] loss: 0.419860785.060200214386[5,  4000] loss: 0.415104792.3774490356445[5,  4500] loss: 0.457058799.6755263805389[5,  5000] loss: 0.434296807.0075216293335[5,  5500] loss: 0.344804814.5181097984314[5,  6000] loss: 0.381049821.8140876293182[5,  6500] loss: 0.406628829.1744730472565[5,  7000] loss: 0.417689836.4653811454773[5,  7500] loss: 0.412821843.8004770278931[5,  8000] loss: 0.412081851.150496006012[5,  8500] loss: 0.385408858.4902806282043[5,  9000] loss: 0.384446865.7621235847473[5,  9500] loss: 0.385620873.0819399356842[5, 10000] loss: 0.416195880.3297595977783[5, 10500] loss: 0.402605887.6213970184326[5, 11000] loss: 0.423432894.9579081535339[5, 11500] loss: 0.375730902.2381689548492[5, 12000] loss: 0.386213909.4968917369843[5, 12500] loss: 0.425698916.756219625473Epoch [5] loss: 1274437.914032Finished TrainingSaving model to /data/s4091221/trained-models/vgg19_bn2020-02-24 21:46:37.606233GroundTruth:    cat  ship  ship planeSending data to GPUSending model to GPUtensor([[-2.1573,  2.6392, -1.1718,  7.3162, -4.6792,  4.9670, -1.1255, -2.3434,         -4.6626,  1.5067],        [ 7.2369,  2.1166, -0.6330,  0.2433, -6.4447, -6.9186, -2.7545, -5.8836,         17.0186, -2.4800],        [ 4.0000,  6.8369, -5.3155, -2.1815, -4.9304, -6.0492, -3.3279, -2.9826,         10.1463,  3.4274],        [ 8.9285, -3.0468,  1.5415,  0.5819, -2.4457, -3.6004, -2.6130, -2.5233,          4.3861, -0.5244]], device='cuda:0', grad_fn=<AddmmBackward>)Predicted:    cat  ship  ship planeAccuracy of the network on the 4000.0 test images: 85 %###########################################################################################################{'use_cuda': True, 'peregrine': True, 'include_visuals': False, 'normalise': False, 'load_from_memory': False, 'pretrain': True, 'batch_size': 4, 'workers': 2, 'model_archi': 7, 'trainset_size': 20000, 'epochs': 5, 'learning_rate': 0.001, 'momentum': 0, 'weight_decay': 0, 'optimizer_choice': 1}Namespace(batch_size=4, epochs=5, include_visuals=False, learning_rate=0.001, load_from_memory=False, model_archi=7, momentum=0, normalise=False, optimizer_choice=1, peregrine=True, pretrain=True, trainset_size=20000, use_cuda=True, weight_decay=0, workers=2)Files already downloaded and verifiedFiles already downloaded and verifiedcuda:012500  dog plane   car  ship['alexnet', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'googlenet', 'inception_v3', 'mnasnet0_5', 'mnasnet0_75', 'mnasnet1_0', 'mnasnet1_3', 'mobilenet_v2', 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50', 'resnext101_32x8d', 'resnext50_32x4d', 'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0', 'shufflenet_v2_x1_5', 'shufflenet_v2_x2_0', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'wide_resnet101_2', 'wide_resnet50_2']Model mnasnet0_5 LoadedMNASNet(  (layers): Sequential(    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)    (1): BatchNorm2d(16, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)    (2): ReLU(inplace=True)    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)    (4): BatchNorm2d(16, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)    (5): ReLU(inplace=True)    (6): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)    (7): BatchNorm2d(8, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)    (8): Sequential(      (0): _InvertedResidual(        (layers): Sequential(          (0): Conv2d(8, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (2): ReLU(inplace=True)          (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)          (4): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (5): ReLU(inplace=True)          (6): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)          (7): BatchNorm2d(16, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)        )      )      (1): _InvertedResidual(        (layers): Sequential(          (0): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (2): ReLU(inplace=True)          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)          (4): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (5): ReLU(inplace=True)          (6): Conv2d(48, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)          (7): BatchNorm2d(16, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)        )      )      (2): _InvertedResidual(        (layers): Sequential(          (0): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (2): ReLU(inplace=True)          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)          (4): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (5): ReLU(inplace=True)          (6): Conv2d(48, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)          (7): BatchNorm2d(16, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)        )      )    )    (9): Sequential(      (0): _InvertedResidual(        (layers): Sequential(          (0): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (2): ReLU(inplace=True)          (3): Conv2d(48, 48, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=48, bias=False)          (4): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (5): ReLU(inplace=True)          (6): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)          (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)        )      )      (1): _InvertedResidual(        (layers): Sequential(          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (2): ReLU(inplace=True)          (3): Conv2d(72, 72, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=72, bias=False)          (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (5): ReLU(inplace=True)          (6): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)          (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)        )      )      (2): _InvertedResidual(        (layers): Sequential(          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (2): ReLU(inplace=True)          (3): Conv2d(72, 72, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=72, bias=False)          (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (5): ReLU(inplace=True)          (6): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)          (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)        )      )    )    (10): Sequential(      (0): _InvertedResidual(        (layers): Sequential(          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(144, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (2): ReLU(inplace=True)          (3): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)          (4): BatchNorm2d(144, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (5): ReLU(inplace=True)          (6): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)          (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)        )      )      (1): _InvertedResidual(        (layers): Sequential(          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (2): ReLU(inplace=True)          (3): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)          (4): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (5): ReLU(inplace=True)          (6): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)          (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)        )      )      (2): _InvertedResidual(        (layers): Sequential(          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (2): ReLU(inplace=True)          (3): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)          (4): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (5): ReLU(inplace=True)          (6): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)          (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)        )      )    )    (11): Sequential(      (0): _InvertedResidual(        (layers): Sequential(          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (2): ReLU(inplace=True)          (3): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)          (4): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (5): ReLU(inplace=True)          (6): Conv2d(240, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)          (7): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)        )      )      (1): _InvertedResidual(        (layers): Sequential(          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(288, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (2): ReLU(inplace=True)          (3): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)          (4): BatchNorm2d(288, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (5): ReLU(inplace=True)          (6): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)          (7): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)        )      )    )    (12): Sequential(      (0): _InvertedResidual(        (layers): Sequential(          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(288, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (2): ReLU(inplace=True)          (3): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)          (4): BatchNorm2d(288, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (5): ReLU(inplace=True)          (6): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)          (7): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)        )      )      (1): _InvertedResidual(        (layers): Sequential(          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (2): ReLU(inplace=True)          (3): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)          (4): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (5): ReLU(inplace=True)          (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)          (7): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)        )      )      (2): _InvertedResidual(        (layers): Sequential(          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (2): ReLU(inplace=True)          (3): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)          (4): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (5): ReLU(inplace=True)          (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)          (7): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)        )      )      (3): _InvertedResidual(        (layers): Sequential(          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (2): ReLU(inplace=True)          (3): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)          (4): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (5): ReLU(inplace=True)          (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)          (7): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)        )      )    )    (13): Sequential(      (0): _InvertedResidual(        (layers): Sequential(          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (2): ReLU(inplace=True)          (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)          (4): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)          (5): ReLU(inplace=True)          (6): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)          (7): BatchNorm2d(160, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)        )      )    )    (14): Conv2d(160, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)    (15): BatchNorm2d(1280, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)    (16): ReLU(inplace=True)  )  (classifier): Linear(in_features=1280, out_features=10, bias=True))Model mnasnet0_5 ReshapedSending model to GPULearning Rate: 0.001, Weight Decay: 0, Momentum: 0Defined <class 'torch.optim.sgd.SGD'> OptimizerStarting Training at 1582577233.083931[1,   500] loss: 2.30434811.026583194732666[1,  1000] loss: 2.30319021.71029305458069[1,  1500] loss: 2.30162732.37524080276489[1,  2000] loss: 2.30174743.00220441818237[1,  2500] loss: 2.30019753.763224840164185[1,  3000] loss: 2.30122064.59971785545349[1,  3500] loss: 2.30034975.53758502006531[1,  4000] loss: 2.29887486.34253406524658[1,  4500] loss: 2.29681997.13539934158325[1,  5000] loss: 2.298601108.09218525886536[1,  5500] loss: 2.295161118.97572326660156[1,  6000] loss: 2.295929129.69331431388855[1,  6500] loss: 2.294425140.41781973838806[1,  7000] loss: 2.294228151.2762303352356[1,  7500] loss: 2.294149162.01285982131958[1,  8000] loss: 2.292557172.81829166412354[1,  8500] loss: 2.293203183.6172230243683[1,  9000] loss: 2.292059194.35920405387878[1,  9500] loss: 2.290864205.2188274860382[1, 10000] loss: 2.288486216.06818175315857[1, 10500] loss: 2.288221227.06289672851562[1, 11000] loss: 2.288885238.16307425498962[1, 11500] loss: 2.288013249.03907990455627[1, 12000] loss: 2.285656259.90191102027893[1, 12500] loss: 2.285256270.8034608364105Epoch [1] loss: 7186961.307058[2,   500] loss: 2.285694281.73937797546387[2,  1000] loss: 2.285956292.63789200782776[2,  1500] loss: 2.283299303.5761294364929[2,  2000] loss: 2.284215314.4656114578247[2,  2500] loss: 2.284000325.49160265922546[2,  3000] loss: 2.283037336.401389837265[2,  3500] loss: 2.283285347.29620242118835[2,  4000] loss: 2.282300358.32183599472046[2,  4500] loss: 2.280351369.2419970035553[2,  5000] loss: 2.281398380.1316981315613[2,  5500] loss: 2.278265391.0299334526062[2,  6000] loss: 2.280027401.89935636520386[2,  6500] loss: 2.279665412.78836727142334[2,  7000] loss: 2.280901423.68718814849854[2,  7500] loss: 2.278237434.6145918369293[2,  8000] loss: 2.276327445.4994215965271[2,  8500] loss: 2.273157456.2672929763794[2,  9000] loss: 2.273796467.08973455429077[2,  9500] loss: 2.274289477.9863061904907[2, 10000] loss: 2.274142488.66747093200684[2, 10500] loss: 2.272331499.51786637306213[2, 11000] loss: 2.273216510.3262257575989[2, 11500] loss: 2.272871521.0877912044525[2, 12000] loss: 2.273827531.8670632839203[2, 12500] loss: 2.271600542.6205389499664Epoch [2] loss: 7134793.820416[3,   500] loss: 2.269372553.5889513492584[3,  1000] loss: 2.272134564.3044447898865[3,  1500] loss: 2.270724574.9937031269073[3,  2000] loss: 2.268807585.668151140213[3,  2500] loss: 2.270142596.4346933364868[3,  3000] loss: 2.267913607.423529624939[3,  3500] loss: 2.268652618.133900642395[3,  4000] loss: 2.273951628.8246173858643[3,  4500] loss: 2.279346639.5786597728729[3,  5000] loss: 2.275283650.3985579013824[3,  5500] loss: 2.273491661.2568547725677[3,  6000] loss: 2.272297672.1563074588776[3,  6500] loss: 2.271207683.1746270656586[3,  7000] loss: 2.269845693.9346585273743[3,  7500] loss: 2.274610704.5836689472198[3,  8000] loss: 2.276554715.3738551139832[3,  8500] loss: 2.270407726.2537615299225[3,  9000] loss: 2.271720736.9204566478729[3,  9500] loss: 2.270693747.8085882663727[3, 10000] loss: 2.268670758.5745191574097[3, 10500] loss: 2.271885769.3045597076416[3, 11000] loss: 2.269436780.1221141815186[3, 11500] loss: 2.270410790.8443565368652[3, 12000] loss: 2.266138801.5722291469574[3, 12500] loss: 2.281742812.2813663482666Epoch [3] loss: 7112354.389605[4,   500] loss: 2.291919823.3337829113007[4,  1000] loss: 2.290562834.3164064884186[4,  1500] loss: 2.292560845.1988799571991[4,  2000] loss: 2.282906856.4101943969727[4,  2500] loss: 2.285155867.2457325458527[4,  3000] loss: 2.286442878.1743955612183[4,  3500] loss: 2.289082889.004753112793[4,  4000] loss: 2.288055899.7501463890076[4,  4500] loss: 2.288630910.5560717582703[4,  5000] loss: 2.285303921.4506523609161[4,  5500] loss: 2.282939932.1990175247192[4,  6000] loss: 2.281367942.9992876052856[4,  6500] loss: 2.285650953.7784674167633[4,  7000] loss: 2.281459964.587938785553[4,  7500] loss: 2.285656975.6079823970795[4,  8000] loss: 2.286952986.3279473781586[4,  8500] loss: 2.284190997.0885219573975[4,  9000] loss: 2.2825661007.8976120948792[4,  9500] loss: 2.2871371018.6943469047546[4, 10000] loss: 2.2845411029.5344576835632[4, 10500] loss: 2.2870391040.3346581459045[4, 11000] loss: 2.2861961051.2911212444305[4, 11500] loss: 2.2881071062.2157621383667[4, 12000] loss: 2.2858901073.1498091220856[4, 12500] loss: 2.2890431083.9830515384674Epoch [4] loss: 7159486.391520[5,   500] loss: 2.2873671095.0788309574127[5,  1000] loss: 2.2811161105.894786119461[5,  1500] loss: 2.2801631116.7678334712982[5,  2000] loss: 2.2856491127.6983091831207[5,  2500] loss: 2.2796101138.5361948013306[5,  3000] loss: 2.2831621149.2949903011322[5,  3500] loss: 2.2847851159.971836090088[5,  4000] loss: 2.2866511170.7012367248535[5,  4500] loss: 2.2888631181.3871006965637[5,  5000] loss: 2.2837411192.098794221878[5,  5500] loss: 2.2889881202.7668595314026[5,  6000] loss: 2.2838621213.507627248764[5,  6500] loss: 2.2817171224.5555081367493[5,  7000] loss: 2.2849281235.3230683803558[5,  7500] loss: 2.2846441245.9730803966522[5,  8000] loss: 2.2823311256.8113222122192[5,  8500] loss: 2.2803091267.6223766803741[5,  9000] loss: 2.2826631278.292349100113[5,  9500] loss: 2.2784731289.1263909339905[5, 10000] loss: 2.2748941299.82834649086[5, 10500] loss: 2.2723571310.6562237739563[5, 11000] loss: 2.2705151321.5991039276123[5, 11500] loss: 2.2707981332.3759334087372[5, 12000] loss: 2.2755971343.6080977916718[5, 12500] loss: 2.2781791354.4808332920074Epoch [5] loss: 7142748.217089Finished TrainingSaving model to /data/s4091221/trained-models/mnasnet0_52020-02-24 22:09:47.621155GroundTruth:    cat  ship  ship planeSending data to GPUSending model to GPUtensor([[-2.6941e-03,  1.0260e-01, -1.1467e-01,  5.2227e-02, -8.4508e-02,         -6.0866e-03, -5.4042e-02,  2.7812e-02,  4.6939e-02,  1.3392e-01],        [-3.4409e-02,  1.9951e-01, -1.2979e-01, -5.9899e-02, -1.9997e-01,         -5.5623e-02, -1.2607e-01, -9.5940e-03,  1.9271e-01,  1.9507e-01],        [ 4.3526e-01,  1.3700e-01,  3.6131e-01, -3.8923e-01, -1.9209e-01,         -3.3369e-01,  2.4677e-01, -9.1166e-02,  4.2357e-01, -2.3227e-01],        [-8.1433e+01,  1.8567e+02,  4.3749e+00, -1.2037e+03, -2.4017e+02,         -4.0768e+02, -4.9827e+00,  3.3521e+02,  3.5886e+02, -1.6393e+02]],       device='cuda:0', grad_fn=<AddmmBackward>)Predicted:  truck   car plane  shipAccuracy of the network on the 4000.0 test images: 10 %###########################################################################################################{'use_cuda': True, 'peregrine': True, 'include_visuals': False, 'normalise': False, 'load_from_memory': False, 'pretrain': True, 'batch_size': 4, 'workers': 2, 'model_archi': 10, 'trainset_size': 20000, 'epochs': 5, 'learning_rate': 0.001, 'momentum': 0, 'weight_decay': 0, 'optimizer_choice': 1}Namespace(batch_size=4, epochs=5, include_visuals=False, learning_rate=0.001, load_from_memory=False, model_archi=10, momentum=0, normalise=False, optimizer_choice=1, peregrine=True, pretrain=True, trainset_size=20000, use_cuda=True, weight_decay=0, workers=2)Files already downloaded and verifiedFiles already downloaded and verifiedcuda:012500truck  bird  ship horse['alexnet', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'googlenet', 'inception_v3', 'mnasnet0_5', 'mnasnet0_75', 'mnasnet1_0', 'mnasnet1_3', 'mobilenet_v2', 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50', 'resnext101_32x8d', 'resnext50_32x4d', 'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0', 'shufflenet_v2_x1_5', 'shufflenet_v2_x2_0', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'wide_resnet101_2', 'wide_resnet50_2']Traceback (most recent call last):  File "./main.py", line 395, in <module>    test(model_names[model_archi])  File "./main.py", line 112, in test    model = models.__dict__[network_architecture](pretrained=pretrain)  File "/home/s4091221/.local/lib/python3.7/site-packages/torchvision/models/mnasnet.py", line 257, in mnasnet1_3    _load_pretrained("mnasnet1_3", model, progress)  File "/home/s4091221/.local/lib/python3.7/site-packages/torchvision/models/mnasnet.py", line 199, in _load_pretrained    "No checkpoint is available for model type {}".format(model_name))ValueError: No checkpoint is available for model type mnasnet1_3###########################################################################################################{'use_cuda': True, 'peregrine': True, 'include_visuals': False, 'normalise': False, 'load_from_memory': False, 'pretrain': True, 'batch_size': 4, 'workers': 2, 'model_archi': 11, 'trainset_size': 20000, 'epochs': 5, 'learning_rate': 0.001, 'momentum': 0, 'weight_decay': 0, 'optimizer_choice': 1}Namespace(batch_size=4, epochs=5, include_visuals=False, learning_rate=0.001, load_from_memory=False, model_archi=11, momentum=0, normalise=False, optimizer_choice=1, peregrine=True, pretrain=True, trainset_size=20000, use_cuda=True, weight_decay=0, workers=2)Files already downloaded and verifiedFiles already downloaded and verifiedcuda:012500 frog  bird  deer  frog['alexnet', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'googlenet', 'inception_v3', 'mnasnet0_5', 'mnasnet0_75', 'mnasnet1_0', 'mnasnet1_3', 'mobilenet_v2', 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50', 'resnext101_32x8d', 'resnext50_32x4d', 'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0', 'shufflenet_v2_x1_5', 'shufflenet_v2_x2_0', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'wide_resnet101_2', 'wide_resnet50_2']Model mobilenet_v2 LoadedMobileNetV2(  (features): Sequential(    (0): ConvBNReLU(      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (2): ReLU6(inplace=True)    )    (1): InvertedResidual(      (conv): Sequential(        (0): ConvBNReLU(          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      )    )    (2): InvertedResidual(      (conv): Sequential(        (0): ConvBNReLU(          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (1): ConvBNReLU(          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      )    )    (3): InvertedResidual(      (conv): Sequential(        (0): ConvBNReLU(          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (1): ConvBNReLU(          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      )    )    (4): InvertedResidual(      (conv): Sequential(        (0): ConvBNReLU(          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (1): ConvBNReLU(          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      )    )    (5): InvertedResidual(      (conv): Sequential(        (0): ConvBNReLU(          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (1): ConvBNReLU(          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      )    )    (6): InvertedResidual(      (conv): Sequential(        (0): ConvBNReLU(          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (1): ConvBNReLU(          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      )    )    (7): InvertedResidual(      (conv): Sequential(        (0): ConvBNReLU(          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (1): ConvBNReLU(          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      )    )    (8): InvertedResidual(      (conv): Sequential(        (0): ConvBNReLU(          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (1): ConvBNReLU(          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      )    )    (9): InvertedResidual(      (conv): Sequential(        (0): ConvBNReLU(          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (1): ConvBNReLU(          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      )    )    (10): InvertedResidual(      (conv): Sequential(        (0): ConvBNReLU(          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (1): ConvBNReLU(          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      )    )    (11): InvertedResidual(      (conv): Sequential(        (0): ConvBNReLU(          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (1): ConvBNReLU(          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      )    )    (12): InvertedResidual(      (conv): Sequential(        (0): ConvBNReLU(          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (1): ConvBNReLU(          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      )    )    (13): InvertedResidual(      (conv): Sequential(        (0): ConvBNReLU(          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (1): ConvBNReLU(          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      )    )    (14): InvertedResidual(      (conv): Sequential(        (0): ConvBNReLU(          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (1): ConvBNReLU(          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      )    )    (15): InvertedResidual(      (conv): Sequential(        (0): ConvBNReLU(          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (1): ConvBNReLU(          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      )    )    (16): InvertedResidual(      (conv): Sequential(        (0): ConvBNReLU(          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (1): ConvBNReLU(          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      )    )    (17): InvertedResidual(      (conv): Sequential(        (0): ConvBNReLU(          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (1): ConvBNReLU(          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          (2): ReLU6(inplace=True)        )        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      )    )    (18): ConvBNReLU(      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)      (2): ReLU6(inplace=True)    )  )  (classifier): Linear(in_features=1280, out_features=10, bias=True))Model mobilenet_v2 ReshapedSending model to GPULearning Rate: 0.001, Weight Decay: 0, Momentum: 0Defined <class 'torch.optim.sgd.SGD'> OptimizerStarting Training at 1582578615.4258616[1,   500] loss: 2.34979211.085863828659058[1,  1000] loss: 2.28390922.032160997390747[1,  1500] loss: 2.26472933.08776307106018[1,  2000] loss: 2.26229743.92018008232117[1,  2500] loss: 2.23383854.85080885887146[1,  3000] loss: 2.24930365.82298016548157[1,  3500] loss: 2.20736876.78226161003113[1,  4000] loss: 2.17497587.6818904876709[1,  4500] loss: 2.16098498.54189944267273[1,  5000] loss: 2.146261109.33348226547241[1,  5500] loss: 2.159399120.12601256370544[1,  6000] loss: 2.140431131.01289653778076[1,  6500] loss: 2.165830142.0569806098938[1,  7000] loss: 2.128664153.17827582359314[1,  7500] loss: 2.120716164.14712834358215[1,  8000] loss: 2.135694175.06895661354065[1,  8500] loss: 2.145365186.0417881011963[1,  9000] loss: 2.146045196.94634437561035[1,  9500] loss: 2.105755207.91951251029968[1, 10000] loss: 2.073132218.96310353279114[1, 10500] loss: 2.068785229.84908533096313[1, 11000] loss: 2.061841240.70731043815613[1, 11500] loss: 2.088927251.85438013076782[1, 12000] loss: 2.103862262.77278327941895[1, 12500] loss: 2.086302273.7137279510498Epoch [1] loss: 6778123.336761[2,   500] loss: 2.153328284.914293050766[2,  1000] loss: 2.146333296.11124563217163[2,  1500] loss: 2.143001307.18717217445374[2,  2000] loss: 2.154916318.2855911254883[2,  2500] loss: 2.152473329.5989191532135[2,  3000] loss: 2.072971340.6749587059021[2,  3500] loss: 2.073534351.74570083618164[2,  4000] loss: 2.057549362.8501753807068[2,  4500] loss: 2.022404373.82059359550476[2,  5000] loss: 2.021935384.93593549728394[2,  5500] loss: 2.066449395.93619203567505[2,  6000] loss: 2.047849407.01543164253235[2,  6500] loss: 2.061625418.1702790260315[2,  7000] loss: 2.096845429.1093623638153[2,  7500] loss: 2.061854440.0488283634186[2,  8000] loss: 2.007470451.29137206077576[2,  8500] loss: 2.033818462.3028173446655[2,  9000] loss: 2.067554473.3129880428314[2,  9500] loss: 2.051446484.13919615745544[2, 10000] loss: 2.051960495.1243076324463[2, 10500] loss: 2.059202506.03091192245483[2, 11000] loss: 2.020377516.7790231704712[2, 11500] loss: 2.015661527.7871632575989[2, 12000] loss: 2.041497538.6972930431366[2, 12500] loss: 2.008144549.5287804603577Epoch [2] loss: 6475563.906918[3,   500] loss: 2.037292560.5756003856659[3,  1000] loss: 1.975526571.543347120285[3,  1500] loss: 1.962175582.6428394317627[3,  2000] loss: 2.008345593.7644736766815[3,  2500] loss: 2.013831604.7256467342377[3,  3000] loss: 2.067265615.6762533187866[3,  3500] loss: 2.042860626.8603994846344[3,  4000] loss: 2.018420637.7330377101898[3,  4500] loss: 2.050340648.7174785137177[3,  5000] loss: 2.009469659.7285327911377[3,  5500] loss: 2.051351670.70317029953[3,  6000] loss: 1.972220681.659476518631[3,  6500] loss: 2.028560692.628847360611[3,  7000] loss: 1.984052703.8039290904999[3,  7500] loss: 2.007258714.9043653011322[3,  8000] loss: 2.029777725.8346903324127[3,  8500] loss: 1.976275736.8165638446808[3,  9000] loss: 1.947987747.7400517463684[3,  9500] loss: 1.910913758.7162351608276[3, 10000] loss: 1.937242769.5639107227325[3, 10500] loss: 1.944341780.614040851593[3, 11000] loss: 1.958137791.653088092804[3, 11500] loss: 1.944668802.684398651123[3, 12000] loss: 1.927946813.7065637111664[3, 12500] loss: 1.909634824.8278260231018Epoch [3] loss: 6222766.969141[4,   500] loss: 1.947947836.0786538124084[4,  1000] loss: 1.908173847.0920977592468[4,  1500] loss: 1.932986857.9655287265778[4,  2000] loss: 1.910914869.0630717277527[4,  2500] loss: 1.895964880.0749087333679[4,  3000] loss: 1.897344891.2235715389252[4,  3500] loss: 1.882288902.3526961803436[4,  4000] loss: 1.887744913.4233510494232[4,  4500] loss: 1.918324924.5666992664337[4,  5000] loss: 1.899752935.7663233280182[4,  5500] loss: 1.899975947.02978515625[4,  6000] loss: 1.934294958.1899936199188[4,  6500] loss: 1.910790969.3297646045685[4,  7000] loss: 1.909574980.4831459522247[4,  7500] loss: 1.946003991.690943479538[4,  8000] loss: 1.9104101002.845912694931[4,  8500] loss: 1.9119881013.9360489845276[4,  9000] loss: 1.8711071025.033761024475[4,  9500] loss: 1.9161131036.0395271778107[4, 10000] loss: 1.8971701047.1147077083588[4, 10500] loss: 1.9110491058.2046840190887[4, 11000] loss: 1.8989011069.4742538928986[4, 11500] loss: 1.8784481080.5135297775269[4, 12000] loss: 1.8771601091.5771729946136[4, 12500] loss: 1.8484081102.7935526371002Epoch [4] loss: 5955702.473732[5,   500] loss: 1.9024461113.9680819511414[5,  1000] loss: 1.9254341124.9936926364899[5,  1500] loss: 1.9154071136.1184561252594[5,  2000] loss: 1.8665101147.299705028534[5,  2500] loss: 2.1458121158.2560527324677[5,  3000] loss: 2.2236961169.2144627571106[5,  3500] loss: 2.1048441180.1936337947845[5,  4000] loss: 2.0827621191.2940208911896[5,  4500] loss: 2.1203871202.4346742630005[5,  5000] loss: 2.0955501213.3592689037323[5,  5500] loss: 2.0666071224.6138708591461[5,  6000] loss: 2.0583571235.7728679180145[5,  6500] loss: 2.0508411246.766892671585[5,  7000] loss: 1.9966861257.8689396381378[5,  7500] loss: 2.0401251268.8426446914673[5,  8000] loss: 2.0395821279.7790377140045[5,  8500] loss: 1.9924991290.6989896297455[5,  9000] loss: 1.9989291301.6484169960022[5,  9500] loss: 1.9812131312.5380856990814[5, 10000] loss: 2.0288311323.674206495285[5, 10500] loss: 1.9821171334.5248756408691[5, 11000] loss: 2.0255671345.3471457958221[5, 11500] loss: 1.9709771356.0847539901733[5, 12000] loss: 1.9437681367.063491821289[5, 12500] loss: 1.9291401378.193148136139Epoch [5] loss: 6314757.657142Finished TrainingSaving model to /data/s4091221/trained-models/mobilenet_v22020-02-24 22:33:13.673807GroundTruth:    cat  ship  ship planeSending data to GPUSending model to GPUtensor([[-1.1372,  0.8327, -0.0691, -0.0666, -0.2133, -0.1548,  1.2615, -0.1256,         -0.7400, -0.5624],        [ 0.6082,  0.7464, -0.7631, -0.7684, -0.5736, -1.1736, -1.4131, -1.1031,          1.7764,  1.1937],        [ 0.1948,  0.2093, -0.1819, -0.5064, -0.0531, -0.4226, -0.7046, -0.2626,          0.8085,  0.6448],        [ 0.6245, -0.0553, -0.0456, -0.2157,  0.0791, -0.2258, -0.6574,  0.1126,          1.0049, -0.0857]], device='cuda:0', grad_fn=<AddmmBackward>)Predicted:   frog  ship  ship  shipAccuracy of the network on the 4000.0 test images: 32 %###############################################################################Peregrine ClusterJob 9730743 for user 's4091221'Finished at: Mon Feb 24 22:33:32 CET 2020Job details:============Name                : step1.shUser                : s4091221Partition           : gpuNodes               : pg-gpu30Cores               : 12State               : COMPLETEDSubmit              : 2020-02-24T17:59:21Start               : 2020-02-24T20:04:32End                 : 2020-02-24T22:33:32Reserved walltime   : 1-06:00:00Used walltime       :   02:29:00Used CPU time       :   02:43:41 (efficiency:  9.15%)% User (Computation): 90.75%% System (I/O)      :  9.24%Mem reserved        : 12000M/nodeMax Mem used        : 2.92G (pg-gpu30)Max Disk Write      : 3.81G (pg-gpu30)Max Disk Read       : 12.07G (pg-gpu30)Acknowledgements:=================Please see this page for information about acknowledging Peregrine in your publications:https://wiki.hpc.rug.nl/peregrine/additional_information/scientific_output################################################################################