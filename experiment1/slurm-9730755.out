Requirement already satisfied: torchvision in ./.local/lib/python3.7/site-packages (0.5.0)
Requirement already satisfied: six in /apps/skylake/software/Python/3.7.4-GCCcore-8.3.0/lib/python3.7/site-packages (from torchvision) (1.12.0)
Requirement already satisfied: pillow>=4.1.1 in ./.local/lib/python3.7/site-packages (from torchvision) (7.0.0)
Requirement already satisfied: torch==1.4.0 in ./.local/lib/python3.7/site-packages (from torchvision) (1.4.0)
Requirement already satisfied: numpy in ./.local/lib/python3.7/site-packages (from torchvision) (1.18.1)
###########################################################################################################
{'use_cuda': True, 'peregrine': True, 'include_visuals': False, 'normalise': False, 'load_from_memory': False, 'pretrain': False, 'batch_size': 4, 'workers': 2, 'model_archi': 1, 'trainset_size': 20000, 'epochs': 20, 'learning_rate': 0.001, 'momentum': 0, 'weight_decay': 0, 'optimizer_choice': 1}
Namespace(batch_size=4, epochs=20, include_visuals=False, learning_rate=0.001, load_from_memory=False, model_archi=1, momentum=0, normalise=False, optimizer_choice=1, peregrine=True, pretrain=False, trainset_size=20000, use_cuda=True, weight_decay=0, workers=2)
Files already downloaded and verified
Files already downloaded and verified
cuda:0
12500
plane   dog   cat  ship
['alexnet', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'googlenet', 'inception_v3', 'mnasnet0_5', 'mnasnet0_75', 'mnasnet1_0', 'mnasnet1_3', 'mobilenet_v2', 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50', 'resnext101_32x8d', 'resnext50_32x4d', 'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0', 'shufflenet_v2_x1_5', 'shufflenet_v2_x2_0', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'wide_resnet101_2', 'wide_resnet50_2']
Model densenet121 Loaded
DenseNet(
  (features): Sequential(
    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu0): ReLU(inplace=True)
    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (denseblock1): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition1): _Transition(
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock2): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition2): _Transition(
      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock3): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer13): _DenseLayer(
        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer14): _DenseLayer(
        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer15): _DenseLayer(
        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer16): _DenseLayer(
        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer17): _DenseLayer(
        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer18): _DenseLayer(
        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer19): _DenseLayer(
        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer20): _DenseLayer(
        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer21): _DenseLayer(
        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer22): _DenseLayer(
        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer23): _DenseLayer(
        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer24): _DenseLayer(
        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition3): _Transition(
      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock4): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer13): _DenseLayer(
        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer14): _DenseLayer(
        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer15): _DenseLayer(
        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer16): _DenseLayer(
        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (classifier): Linear(in_features=1024, out_features=1000, bias=True)
)
Model densenet121 Reshaped
Sending model to GPU
Learning Rate: 0.001, Weight Decay: 0, Momentum: 0
Defined <class 'torch.optim.sgd.SGD'> Optimizer
Starting Training at 1582574517.05912
[1,   500] loss: 3.784160
34.3058295249939
[1,  1000] loss: 2.344053
66.48083758354187
[1,  1500] loss: 2.236074
98.87606287002563
[1,  2000] loss: 2.205948
130.6990773677826
[1,  2500] loss: 2.156209
162.69266057014465
[1,  3000] loss: 2.135358
194.83063411712646
[1,  3500] loss: 2.100478
227.63204503059387
[1,  4000] loss: 2.121679
259.63694429397583
[1,  4500] loss: 2.097325
291.65557622909546
[1,  5000] loss: 2.080387
323.8059461116791
[1,  5500] loss: 2.059194
355.99794340133667
[1,  6000] loss: 2.044901
388.0735282897949
[1,  6500] loss: 2.023110
420.21969532966614
[1,  7000] loss: 2.035587
452.2155818939209
[1,  7500] loss: 1.991891
484.44350838661194
[1,  8000] loss: 2.009724
516.3568780422211
[1,  8500] loss: 1.997333
548.1485757827759
[1,  9000] loss: 1.980652
580.1859741210938
[1,  9500] loss: 1.999598
612.1738967895508
[1, 10000] loss: 1.957194
644.7394468784332
[1, 10500] loss: 1.967726
676.5298664569855
[1, 11000] loss: 1.959690
708.3819916248322
[1, 11500] loss: 1.935100
740.7828416824341
[1, 12000] loss: 1.958148
772.9355916976929
[1, 12500] loss: 1.913739
805.4294440746307
Epoch [1] loss: 6757034.830700
[2,   500] loss: 1.905344
837.6773364543915
[2,  1000] loss: 1.907726
869.6952571868896
[2,  1500] loss: 1.930210
902.1226575374603
[2,  2000] loss: 1.914944
934.7046520709991
[2,  2500] loss: 1.920749
967.326541185379
[2,  3000] loss: 1.912730
999.1336703300476
[2,  3500] loss: 1.887407
1030.977386713028
[2,  4000] loss: 1.933846
1063.1121108531952
[2,  4500] loss: 1.970213
1095.2436213493347
[2,  5000] loss: 1.951546
1127.6024796962738
[2,  5500] loss: 1.915578
1159.6670033931732
[2,  6000] loss: 1.920779
1191.5807337760925
[2,  6500] loss: 1.898879
1224.0502457618713
[2,  7000] loss: 1.924575
1256.2030758857727
[2,  7500] loss: 1.907688
1288.5968952178955
[2,  8000] loss: 1.820783
1320.6629066467285
[2,  8500] loss: 1.852136
1352.7148611545563
[2,  9000] loss: 1.896403
1384.7604024410248
[2,  9500] loss: 1.845803
1416.9529485702515
[2, 10000] loss: 1.861170
1448.8758916854858
[2, 10500] loss: 1.873120
1480.8953731060028
[2, 11000] loss: 1.860855
1513.1066060066223
[2, 11500] loss: 1.862957
1545.0077166557312
[2, 12000] loss: 1.828457
1577.5428807735443
[2, 12500] loss: 1.815315
1610.3346617221832
Epoch [2] loss: 5946568.194387
[3,   500] loss: 1.818970
1642.3376631736755
[3,  1000] loss: 1.817349
1674.3886096477509
[3,  1500] loss: 1.811252
1706.149166584015
[3,  2000] loss: 1.823252
1738.726235628128
[3,  2500] loss: 1.826053
1770.650202035904
[3,  3000] loss: 1.796910
1802.777880191803
[3,  3500] loss: 1.780010
1834.7820613384247
[3,  4000] loss: 1.808627
1866.8610937595367
[3,  4500] loss: 1.806892
1898.8833360671997
[3,  5000] loss: 1.780155
1931.0760374069214
[3,  5500] loss: 1.818019
1963.1198437213898
[3,  6000] loss: 1.780838
1995.1207208633423
[3,  6500] loss: 1.777749
2027.2649502754211
[3,  7000] loss: 1.809835
2059.2814321517944
[3,  7500] loss: 1.743473
2091.4776780605316
[3,  8000] loss: 1.719657
2124.1946799755096
[3,  8500] loss: 1.727278
2156.1291761398315
[3,  9000] loss: 1.771320
2189.1954758167267
[3,  9500] loss: 1.766160
2220.972176551819
[3, 10000] loss: 1.765499
2253.1806576251984
[3, 10500] loss: 1.755685
2285.462568998337
[3, 11000] loss: 1.764895
2318.1607706546783
[3, 11500] loss: 1.724906
2350.5072882175446
[3, 12000] loss: 1.772877
2382.855660200119
[3, 12500] loss: 1.766421
2415.0671870708466
Epoch [3] loss: 5590630.684659
[4,   500] loss: 1.744874
2447.232958316803
[4,  1000] loss: 1.707713
2479.2592537403107
[4,  1500] loss: 1.713794
2511.1555535793304
[4,  2000] loss: 1.710695
2543.6432077884674
[4,  2500] loss: 1.739908
2575.8769891262054
[4,  3000] loss: 1.697037
2608.0891864299774
[4,  3500] loss: 1.701014
2640.4594514369965
[4,  4000] loss: 1.699708
2673.465348482132
[4,  4500] loss: 1.665502
2706.16349029541
[4,  5000] loss: 1.681266
2738.159476041794
[4,  5500] loss: 1.710463
2770.3991978168488
[4,  6000] loss: 1.728708
2803.728960752487
[4,  6500] loss: 1.647141
2836.1895372867584
[4,  7000] loss: 1.695759
2868.5675809383392
[4,  7500] loss: 1.645759
2900.639230966568
[4,  8000] loss: 1.716667
2932.6379866600037
[4,  8500] loss: 1.654885
2964.9807155132294
[4,  9000] loss: 1.683875
2997.455968618393
[4,  9500] loss: 1.669567
3029.602037668228
[4, 10000] loss: 1.616651
3061.8344581127167
[4, 10500] loss: 1.639555
3094.290529727936
[4, 11000] loss: 1.681189
3126.2204077243805
[4, 11500] loss: 1.663007
3158.2536492347717
[4, 12000] loss: 1.680553
3190.3568153381348
[4, 12500] loss: 1.643293
3222.7779717445374
Epoch [4] loss: 5272818.874109
[5,   500] loss: 1.637043
3255.375351190567
[5,  1000] loss: 1.648024
3287.4003574848175
[5,  1500] loss: 1.599794
3319.611478805542
[5,  2000] loss: 1.651202
3351.9903535842896
[5,  2500] loss: 1.607692
3384.0001695156097
[5,  3000] loss: 1.626896
3415.8868532180786
[5,  3500] loss: 1.638400
3448.5432221889496
[5,  4000] loss: 1.648331
3480.5960545539856
[5,  4500] loss: 1.619353
3512.4541704654694
[5,  5000] loss: 1.602197
3544.347868680954
[5,  5500] loss: 1.650319
3576.373571872711
[5,  6000] loss: 1.606016
3608.7700338363647
[5,  6500] loss: 1.600326
3640.524251461029
[5,  7000] loss: 1.606148
3672.3449261188507
[5,  7500] loss: 1.611433
3704.6207525730133
[5,  8000] loss: 1.618803
3736.4789774417877
[5,  8500] loss: 1.622596
3768.2616333961487
[5,  9000] loss: 1.605376
3801.8387072086334
[5,  9500] loss: 1.599185
3833.8781497478485
[5, 10000] loss: 1.582199
3866.089605808258
[5, 10500] loss: 1.563507
3898.341537952423
[5, 11000] loss: 1.564784
3931.6306524276733
[5, 11500] loss: 1.563081
3963.657422542572
[5, 12000] loss: 1.556538
3995.961944580078
[5, 12500] loss: 1.628920
4028.000513792038
Epoch [5] loss: 5051413.228499
[6,   500] loss: 1.570521
4060.7838497161865
[6,  1000] loss: 1.531532
4092.987211227417
[6,  1500] loss: 1.586867
4125.25311756134
[6,  2000] loss: 1.572118
4157.558002471924
[6,  2500] loss: 1.542058
4189.481595277786
[6,  3000] loss: 1.563533
4221.234821557999
[6,  3500] loss: 1.554970
4253.079254388809
[6,  4000] loss: 1.528011
4285.296175003052
[6,  4500] loss: 1.523499
4317.2988204956055
[6,  5000] loss: 1.581881
4348.959698915482
[6,  5500] loss: 1.569778
4380.942795753479
[6,  6000] loss: 1.535304
4413.423274278641
[6,  6500] loss: 1.510598
4445.2379813194275
[6,  7000] loss: 1.549868
4477.239591121674
[6,  7500] loss: 1.569240
4509.582066297531
[6,  8000] loss: 1.565829
4541.571431875229
[6,  8500] loss: 1.545123
4574.1240656375885
[6,  9000] loss: 1.512696
4606.158928632736
[6,  9500] loss: 1.553684
4638.0148665905
[6, 10000] loss: 1.541692
4670.255641698837
[6, 10500] loss: 1.477026
4702.202637910843
[6, 11000] loss: 1.563709
4734.448118686676
[6, 11500] loss: 1.558787
4766.071559429169
[6, 12000] loss: 1.528251
4798.332237958908
[6, 12500] loss: 1.535717
4830.403749227524
Epoch [6] loss: 4828414.737978
[7,   500] loss: 1.511769
4862.670933485031
[7,  1000] loss: 1.487676
4894.71466255188
[7,  1500] loss: 1.474806
4926.718140602112
[7,  2000] loss: 1.499968
4958.797340154648
[7,  2500] loss: 1.462561
4990.7479865550995
[7,  3000] loss: 1.497778
5022.639716386795
[7,  3500] loss: 1.493385
5054.8659055233
[7,  4000] loss: 1.435289
5087.285999059677
[7,  4500] loss: 1.516881
5119.205347776413
[7,  5000] loss: 1.545386
5151.184164762497
[7,  5500] loss: 1.518663
5182.956767082214
[7,  6000] loss: 1.493676
5215.312038898468
[7,  6500] loss: 1.509529
5247.0898241996765
[7,  7000] loss: 1.498392
5279.335927248001
[7,  7500] loss: 1.478669
5312.529722929001
[7,  8000] loss: 1.486033
5345.1915328502655
[7,  8500] loss: 1.450612
5376.9236307144165
[7,  9000] loss: 1.472326
5408.924524068832
[7,  9500] loss: 1.447108
5440.646708726883
[7, 10000] loss: 1.454164
5473.097607851028
[7, 10500] loss: 1.451818
5505.08767414093
[7, 11000] loss: 1.469876
5536.965918540955
[7, 11500] loss: 1.445237
5569.515741586685
[7, 12000] loss: 1.434650
5601.837724208832
[7, 12500] loss: 1.393160
5634.094351530075
Epoch [7] loss: 4622110.898915
[8,   500] loss: 1.438053
5666.31351184845
[8,  1000] loss: 1.416257
5698.4523713588715
[8,  1500] loss: 1.444213
5730.566205024719
[8,  2000] loss: 1.424447
5762.871493339539
[8,  2500] loss: 1.437268
5794.653075933456
[8,  3000] loss: 1.445004
5826.561357021332
[8,  3500] loss: 1.438544
5858.943881511688
[8,  4000] loss: 1.461875
5890.809646606445
[8,  4500] loss: 1.459355
5922.95167183876
[8,  5000] loss: 1.456304
5955.24120092392
[8,  5500] loss: 1.401316
5987.971148490906
[8,  6000] loss: 1.444349
6020.295990228653
[8,  6500] loss: 1.400236
6053.145142316818
[8,  7000] loss: 1.433526
6085.306294441223
[8,  7500] loss: 1.375565
6118.042041063309
[8,  8000] loss: 1.369420
6150.384395599365
[8,  8500] loss: 1.400283
6182.945177078247
[8,  9000] loss: 1.357687
6215.260515213013
[8,  9500] loss: 1.404760
6247.620079755783
[8, 10000] loss: 1.400467
6280.369968175888
[8, 10500] loss: 1.384006
6312.703733921051
[8, 11000] loss: 1.392213
6345.11994934082
[8, 11500] loss: 1.393545
6377.818037509918
[8, 12000] loss: 1.421176
6410.694773674011
[8, 12500] loss: 1.412526
6443.015887022018
Epoch [8] loss: 4442287.500725
[9,   500] loss: 1.359521
6475.439633369446
[9,  1000] loss: 1.447124
6508.050924062729
[9,  1500] loss: 1.339998
6540.634206056595
[9,  2000] loss: 1.368607
6573.313395500183
[9,  2500] loss: 1.337386
6605.747533321381
[9,  3000] loss: 1.342925
6638.276960372925
[9,  3500] loss: 1.336603
6670.388974428177
[9,  4000] loss: 1.397752
6702.2408130168915
[9,  4500] loss: 1.382045
6734.77499127388
[9,  5000] loss: 1.339072
6768.004291534424
[9,  5500] loss: 1.352983
6801.281731843948
[9,  6000] loss: 1.410373
6834.626324176788
[9,  6500] loss: 1.339154
6868.303937673569
[9,  7000] loss: 1.411950
6902.112180233002
[9,  7500] loss: 1.388885
6935.679493904114
[9,  8000] loss: 1.391142
6968.7843108177185
[9,  8500] loss: 1.317353
7001.838744163513
[9,  9000] loss: 1.328126
7034.810169935226
[9,  9500] loss: 1.348545
7068.220447301865
[9, 10000] loss: 1.309916
7102.074639797211
[9, 10500] loss: 1.347134
7135.75287437439
[9, 11000] loss: 1.327092
7169.312549114227
[9, 11500] loss: 1.348762
7202.866729259491
[9, 12000] loss: 1.363627
7236.478073596954
[9, 12500] loss: 1.355673
7270.095351696014
Epoch [9] loss: 4243335.411874
[10,   500] loss: 1.315356
7303.485123872757
[10,  1000] loss: 1.327274
7336.892782449722
[10,  1500] loss: 1.293235
7370.024491548538
[10,  2000] loss: 1.386151
7403.3486959934235
[10,  2500] loss: 1.328909
7437.147691965103
[10,  3000] loss: 1.259862
7470.27109670639
[10,  3500] loss: 1.349282
7503.983726739883
[10,  4000] loss: 1.321514
7537.9598779678345
[10,  4500] loss: 1.347114
7571.9804582595825
[10,  5000] loss: 1.348897
7605.328776597977
[10,  5500] loss: 1.352409
7638.8048939704895
[10,  6000] loss: 1.331758
7673.148659944534
[10,  6500] loss: 1.317215
7706.961755514145
[10,  7000] loss: 1.297851
7740.293173789978
[10,  7500] loss: 1.272033
7774.0760061740875
[10,  8000] loss: 1.251418
7808.398325443268
[10,  8500] loss: 1.286303
7842.0985651016235
[10,  9000] loss: 1.274660
7875.726855754852
[10,  9500] loss: 1.282466
7909.349094152451
[10, 10000] loss: 1.284876
7944.876561164856
[10, 10500] loss: 1.276090
7978.3862471580505
[10, 11000] loss: 1.366451
8012.112626075745
[10, 11500] loss: 1.294618
8045.4480311870575
[10, 12000] loss: 1.276285
8079.424498081207
[10, 12500] loss: 1.315343
8113.406467914581
Epoch [10] loss: 4119315.894757
[11,   500] loss: 1.234724
8148.464823722839
[11,  1000] loss: 1.257479
8182.476547718048
[11,  1500] loss: 1.309717
8216.243359565735
[11,  2000] loss: 1.272365
8250.03723359108
[11,  2500] loss: 1.252562
8284.07553243637
[11,  3000] loss: 1.280250
8318.18397283554
[11,  3500] loss: 1.325458
8352.316547632217
[11,  4000] loss: 1.279573
8386.33744597435
[11,  4500] loss: 1.237423
8420.267571926117
[11,  5000] loss: 1.216419
8453.995042085648
[11,  5500] loss: 1.266232
8487.746662855148
[11,  6000] loss: 1.206824
8521.74674987793
[11,  6500] loss: 1.275371
8555.581503629684
[11,  7000] loss: 1.305475
8589.696028232574
[11,  7500] loss: 1.274688
8623.671465158463
[11,  8000] loss: 1.254264
8657.496584892273
[11,  8500] loss: 1.305334
8691.446581602097
[11,  9000] loss: 1.271169
8724.998388528824
[11,  9500] loss: 1.281605
8760.172056913376
[11, 10000] loss: 1.306474
8793.93895483017
[11, 10500] loss: 1.280672
8827.643941640854
[11, 11000] loss: 1.239441
8861.331495046616
[11, 11500] loss: 1.267783
8895.347529649734
[11, 12000] loss: 1.307537
8928.89949631691
[11, 12500] loss: 1.291285
8962.740247249603
Epoch [11] loss: 3988408.367543
[12,   500] loss: 1.250551
8997.195412158966
[12,  1000] loss: 1.277346
9031.51990890503
[12,  1500] loss: 1.232407
9065.333169698715
[12,  2000] loss: 1.245030
9099.25628399849
[12,  2500] loss: 1.187562
9133.330979347229
[12,  3000] loss: 1.211720
9167.075786828995
[12,  3500] loss: 1.260465
9200.830476045609
[12,  4000] loss: 1.265484
9234.912467479706
[12,  4500] loss: 1.221034
9268.666585683823
[12,  5000] loss: 1.212961
9302.815966129303
[12,  5500] loss: 1.242100
9336.891467571259
[12,  6000] loss: 1.256626
9370.601964712143
[12,  6500] loss: 1.177479
9404.517614603043
[12,  7000] loss: 1.215274
9438.460397720337
[12,  7500] loss: 1.208392
9472.260331630707
[12,  8000] loss: 1.249912
9506.376151561737
[12,  8500] loss: 1.258802
9539.82920718193
[12,  9000] loss: 1.221246
9573.69067621231
[12,  9500] loss: 1.241017
9607.778684854507
[12, 10000] loss: 1.224165
9641.707026004791
[12, 10500] loss: 1.245383
9675.390625953674
[12, 11000] loss: 1.211675
9709.354521512985
[12, 11500] loss: 1.231704
9743.182996988297
[12, 12000] loss: 1.198773
9776.767897605896
[12, 12500] loss: 1.197400
9810.595648765564
Epoch [12] loss: 3850534.333202
[13,   500] loss: 1.223573
9844.396398305893
[13,  1000] loss: 1.163941
9878.29378938675
[13,  1500] loss: 1.271350
9912.72088098526
[13,  2000] loss: 1.232014
9946.611674308777
[13,  2500] loss: 1.154202
9980.888092756271
[13,  3000] loss: 1.203896
10014.674305200577
[13,  3500] loss: 1.188733
10048.52971625328
[13,  4000] loss: 1.231720
10082.550329685211
[13,  4500] loss: 1.198634
10116.588330507278
[13,  5000] loss: 1.108998
10150.447473287582
[13,  5500] loss: 1.216621
10184.358212471008
[13,  6000] loss: 1.218649
10218.629601478577
[13,  6500] loss: 1.138206
10252.40067577362
[13,  7000] loss: 1.148336
10286.26335144043
[13,  7500] loss: 1.201497
10320.14343714714
[13,  8000] loss: 1.151674
10354.0908639431
[13,  8500] loss: 1.199845
10387.839698553085
[13,  9000] loss: 1.178417
10421.766627311707
[13,  9500] loss: 1.172170
10455.657663822174
[13, 10000] loss: 1.193491
10489.831142187119
[13, 10500] loss: 1.170131
10523.75138092041
[13, 11000] loss: 1.138649
10557.104468345642
[13, 11500] loss: 1.178053
10591.056626558304
[13, 12000] loss: 1.178905
10624.786600112915
[13, 12500] loss: 1.161688
10658.717620372772
Epoch [13] loss: 3707623.035155
[14,   500] loss: 1.136557
10692.842559337616
[14,  1000] loss: 1.164768
10727.090422868729
[14,  1500] loss: 1.140074
10761.149465560913
[14,  2000] loss: 1.162466
10795.725041389465
[14,  2500] loss: 1.170170
10830.14474272728
[14,  3000] loss: 1.103327
10864.077471256256
[14,  3500] loss: 1.179461
10897.797189235687
[14,  4000] loss: 1.099081
10931.71502661705
[14,  4500] loss: 1.100948
10965.380401134491
[14,  5000] loss: 1.152599
10999.285063028336
[14,  5500] loss: 1.138272
11033.737437963486
[14,  6000] loss: 1.142306
11067.829204320908
[14,  6500] loss: 1.155667
11102.099710464478
[14,  7000] loss: 1.140358
11136.069303750992
[14,  7500] loss: 1.115870
11170.22771191597
[14,  8000] loss: 1.197208
11203.936270475388
[14,  8500] loss: 1.125729
11238.161770105362
[14,  9000] loss: 1.128437
11271.655547857285
[14,  9500] loss: 1.095678
11305.582510471344
[14, 10000] loss: 1.138008
11339.530823469162
[14, 10500] loss: 1.137410
11373.72663474083
[14, 11000] loss: 1.109883
11407.575979471207
[14, 11500] loss: 1.123299
11441.431401968002
[14, 12000] loss: 1.142614
11475.532799959183
[14, 12500] loss: 1.098321
11509.4410135746
Epoch [14] loss: 3561403.650442
[15,   500] loss: 1.177490
11543.710148334503
[15,  1000] loss: 1.088962
11577.963490009308
[15,  1500] loss: 1.142566
11612.096576929092
[15,  2000] loss: 1.104879
11645.858746290207
[15,  2500] loss: 1.106865
11679.744943857193
[15,  3000] loss: 1.091728
11713.656096220016
[15,  3500] loss: 1.117126
11747.922068119049
[15,  4000] loss: 1.115614
11781.785214662552
[15,  4500] loss: 1.119511
11816.110899925232
[15,  5000] loss: 1.079496
11850.16126704216
[15,  5500] loss: 1.125171
11884.074157476425
[15,  6000] loss: 1.131082
11918.284450769424
[15,  6500] loss: 1.075483
11952.504164218903
[15,  7000] loss: 1.074553
11986.616034984589
[15,  7500] loss: 1.114955
12020.574090480804
[15,  8000] loss: 1.121665
12054.421519756317
[15,  8500] loss: 1.163540
12089.045396089554
[15,  9000] loss: 1.080075
12122.980172395706
[15,  9500] loss: 1.073395
12156.897361755371
[15, 10000] loss: 1.129311
12190.917525529861
[15, 10500] loss: 1.142806
12225.102144002914
[15, 11000] loss: 1.100042
12259.363981246948
[15, 11500] loss: 1.134383
12292.812978506088
[15, 12000] loss: 1.152330
12326.836916446686
[15, 12500] loss: 1.048660
12360.542175531387
Epoch [15] loss: 3494480.999524
[16,   500] loss: 1.074535
12396.565264940262
[16,  1000] loss: 1.064252
12430.357319831848
[16,  1500] loss: 1.072467
12464.00086236
[16,  2000] loss: 1.052605
12498.009178876877
[16,  2500] loss: 1.086638
12531.955101966858
[16,  3000] loss: 1.081915
12565.670665979385
[16,  3500] loss: 1.043736
12599.695071220398
[16,  4000] loss: 1.094464
12633.736544847488
[16,  4500] loss: 1.059984
12667.46957230568
[16,  5000] loss: 1.084165
12701.35553407669
[16,  5500] loss: 1.068185
12735.273705244064
[16,  6000] loss: 1.075069
12769.259080648422
[16,  6500] loss: 1.061800
12802.960098981857
[16,  7000] loss: 1.078793
12836.926981449127
[16,  7500] loss: 1.097156
12871.465326070786
[16,  8000] loss: 1.080946
12905.840691328049
[16,  8500] loss: 1.043759
12940.114499092102
[16,  9000] loss: 1.068153
12974.133907318115
[16,  9500] loss: 1.075835
13007.833106517792
[16, 10000] loss: 1.083759
13042.024686574936
[16, 10500] loss: 1.088556
13075.798710823059
[16, 11000] loss: 1.046650
13109.80916595459
[16, 11500] loss: 1.050981
13143.926548242569
[16, 12000] loss: 1.061414
13177.755316495895
[16, 12500] loss: 1.062042
13211.959177732468
Epoch [16] loss: 3353724.283570
[17,   500] loss: 1.031353
13247.217736721039
[17,  1000] loss: 1.018979
13281.05484342575
[17,  1500] loss: 0.997952
13314.918221712112
[17,  2000] loss: 1.049185
13348.967313289642
[17,  2500] loss: 1.044596
13382.878374099731
[17,  3000] loss: 1.019406
13416.821652650833
[17,  3500] loss: 1.054032
13450.429956912994
[17,  4000] loss: 1.040546
13484.406953811646
[17,  4500] loss: 0.997126
13518.436173439026
[17,  5000] loss: 1.008027
13552.012703895569
[17,  5500] loss: 1.080999
13586.183511734009
[17,  6000] loss: 1.038526
13620.191812753677
[17,  6500] loss: 1.043567
13654.328946590424
[17,  7000] loss: 1.008865
13688.108771562576
[17,  7500] loss: 1.023508
13722.339179754257
[17,  8000] loss: 1.009703
13757.122995138168
[17,  8500] loss: 1.079760
13791.82943224907
[17,  9000] loss: 1.019683
13826.137861967087
[17,  9500] loss: 1.028055
13860.265780687332
[17, 10000] loss: 1.004747
13894.182775259018
[17, 10500] loss: 1.031557
13927.953960895538
[17, 11000] loss: 1.071406
13961.482751369476
[17, 11500] loss: 1.023442
13995.160253047943
[17, 12000] loss: 1.039262
14028.884904146194
[17, 12500] loss: 1.047824
14062.95159482956
Epoch [17] loss: 3223468.192721
[18,   500] loss: 0.995034
14096.788342475891
[18,  1000] loss: 0.986273
14130.383781671524
[18,  1500] loss: 0.990458
14163.872709274292
[18,  2000] loss: 0.991534
14197.977251529694
[18,  2500] loss: 0.982883
14231.704567193985
[18,  3000] loss: 0.969017
14265.430177927017
[18,  3500] loss: 0.994204
14299.290096521378
[18,  4000] loss: 1.039103
14332.910798072815
[18,  4500] loss: 1.013467
14366.593377113342
[18,  5000] loss: 0.979410
14400.251249551773
[18,  5500] loss: 0.981054
14433.778778553009
[18,  6000] loss: 1.056310
14467.46358180046
[18,  6500] loss: 0.984240
14501.20974612236
[18,  7000] loss: 1.016346
14534.947638750076
[18,  7500] loss: 0.998185
14569.000080823898
[18,  8000] loss: 0.984724
14603.628413677216
[18,  8500] loss: 1.003812
14637.753704547882
[18,  9000] loss: 0.947649
14671.785892248154
[18,  9500] loss: 0.972855
14705.307641029358
[18, 10000] loss: 0.988729
14739.413935184479
[18, 10500] loss: 1.004046
14773.281521081924
[18, 11000] loss: 0.993745
14807.003296375275
[18, 11500] loss: 1.007765
14840.431523799896
[18, 12000] loss: 1.048390
14873.90387225151
[18, 12500] loss: 1.004920
14907.121372461319
Epoch [18] loss: 3125918.642724
[19,   500] loss: 1.014106
14939.155628681183
[19,  1000] loss: 0.990055
14970.964946985245
[19,  1500] loss: 0.965728
15002.749371528625
[19,  2000] loss: 0.936964
15034.747792005539
[19,  2500] loss: 0.931446
15067.028308153152
[19,  3000] loss: 0.937694
15098.643662452698
[19,  3500] loss: 1.016783
15130.11621928215
[19,  4000] loss: 0.950510
15161.676785945892
[19,  4500] loss: 1.036821
15193.859548091888
[19,  5000] loss: 0.920878
15225.666474342346
[19,  5500] loss: 0.979876
15257.064960718155
[19,  6000] loss: 0.984360
15289.41772890091
[19,  6500] loss: 0.945034
15321.15170121193
[19,  7000] loss: 0.932729
15352.764246463776
[19,  7500] loss: 0.982462
15384.356838226318
[19,  8000] loss: 1.014034
15416.12682557106
[19,  8500] loss: 1.013980
15447.62334227562
[19,  9000] loss: 0.964005
15479.54596543312
[19,  9500] loss: 1.007689
15511.196013212204
[19, 10000] loss: 0.971057
15543.492821216583
[19, 10500] loss: 0.974569
15574.952909708023
[19, 11000] loss: 0.990692
15606.810156106949
[19, 11500] loss: 0.970899
15638.74072599411
[19, 12000] loss: 0.993022
15670.139012813568
[19, 12500] loss: 0.970601
15701.787750005722
Epoch [19] loss: 3068341.076801
[20,   500] loss: 0.962562
15733.631679058075
[20,  1000] loss: 0.953913
15765.540600061417
[20,  1500] loss: 0.995861
15797.547283649445
[20,  2000] loss: 0.966791
15829.123590946198
[20,  2500] loss: 0.961419
15860.601087331772
[20,  3000] loss: 0.955333
15892.559919118881
[20,  3500] loss: 0.877570
15924.365659236908
[20,  4000] loss: 0.948476
15956.534126520157
[20,  4500] loss: 0.929335
15988.34732723236
[20,  5000] loss: 0.974893
16020.435787439346
[20,  5500] loss: 0.992267
16051.96881866455
[20,  6000] loss: 0.935781
16083.549201250076
[20,  6500] loss: 0.905282
16115.221257925034
[20,  7000] loss: 0.950079
16146.582980632782
[20,  7500] loss: 0.910335
16177.999868392944
[20,  8000] loss: 0.913988
16209.843088626862
[20,  8500] loss: 0.956189
16241.10613822937
[20,  9000] loss: 0.930927
16274.23407125473
[20,  9500] loss: 0.956249
16310.266350269318
[20, 10000] loss: 0.913393
16341.743393421173
[20, 10500] loss: 0.969982
16373.121929645538
[20, 11000] loss: 0.937894
16404.829744815826
[20, 11500] loss: 0.935987
16436.3781542778
[20, 12000] loss: 0.923337
16468.507207393646
[20, 12500] loss: 0.984724
16500.72118616104
Epoch [20] loss: 2977157.636743
Finished Training
Saving model to /data/s4091221/trained-models/densenet1212020-02-25 01:36:57.824798
GroundTruth:    cat  ship  ship plane
Sending data to GPU
Sending model to GPU
tensor([[ 1.0080e+01,  7.9305e+00,  9.5869e+00,  ..., -1.3867e-01,
         -1.2159e-01,  3.6645e-02],
        [ 1.5349e+01,  1.5146e+01,  9.7507e+00,  ...,  4.1346e-02,
          2.7139e-02, -2.8372e-01],
        [ 1.2077e+01,  1.0774e+01,  9.3171e+00,  ...,  6.3238e-02,
          4.0971e-03,  1.0383e-01],
        [ 1.7143e+01,  1.0847e+01,  1.3376e+01,  ..., -1.1937e-01,
         -2.1788e-01, -3.6428e-01]], device='cuda:0', grad_fn=<AddmmBackward>)
Predicted:    dog  ship  ship plane
Accuracy of the network on the 4000.0 test images: 68 %
###########################################################################################################
{'use_cuda': True, 'peregrine': True, 'include_visuals': False, 'normalise': False, 'load_from_memory': False, 'pretrain': True, 'batch_size': 4, 'workers': 2, 'model_archi': 1, 'trainset_size': 20000, 'epochs': 20, 'learning_rate': 0.001, 'momentum': 0, 'weight_decay': 0, 'optimizer_choice': 1}
Namespace(batch_size=4, epochs=20, include_visuals=False, learning_rate=0.001, load_from_memory=False, model_archi=1, momentum=0, normalise=False, optimizer_choice=1, peregrine=True, pretrain=True, trainset_size=20000, use_cuda=True, weight_decay=0, workers=2)
Files already downloaded and verified
Files already downloaded and verified
cuda:0
12500
plane  ship plane   cat
['alexnet', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'googlenet', 'inception_v3', 'mnasnet0_5', 'mnasnet0_75', 'mnasnet1_0', 'mnasnet1_3', 'mobilenet_v2', 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50', 'resnext101_32x8d', 'resnext50_32x4d', 'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0', 'shufflenet_v2_x1_5', 'shufflenet_v2_x2_0', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'wide_resnet101_2', 'wide_resnet50_2']
Model densenet121 Loaded
DenseNet(
  (features): Sequential(
    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu0): ReLU(inplace=True)
    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (denseblock1): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition1): _Transition(
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock2): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition2): _Transition(
      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock3): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer13): _DenseLayer(
        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer14): _DenseLayer(
        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer15): _DenseLayer(
        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer16): _DenseLayer(
        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer17): _DenseLayer(
        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer18): _DenseLayer(
        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer19): _DenseLayer(
        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer20): _DenseLayer(
        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer21): _DenseLayer(
        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer22): _DenseLayer(
        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer23): _DenseLayer(
        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer24): _DenseLayer(
        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition3): _Transition(
      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock4): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer13): _DenseLayer(
        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer14): _DenseLayer(
        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer15): _DenseLayer(
        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer16): _DenseLayer(
        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (classifier): Linear(in_features=1024, out_features=1000, bias=True)
)
Model densenet121 Reshaped
Sending model to GPU
Learning Rate: 0.001, Weight Decay: 0, Momentum: 0
Defined <class 'torch.optim.sgd.SGD'> Optimizer
Starting Training at 1582591096.7117267
[1,   500] loss: 3.899885
33.16430997848511
[1,  1000] loss: 2.474583
64.99546909332275
[1,  1500] loss: 2.240677
96.77308678627014
[1,  2000] loss: 2.130158
128.5238687992096
[1,  2500] loss: 2.075796
159.9549322128296
[1,  3000] loss: 2.046152
191.9686360359192
[1,  3500] loss: 2.009130
223.64314126968384
[1,  4000] loss: 1.940039
255.31092929840088
[1,  4500] loss: 1.979227
287.0217740535736
[1,  5000] loss: 1.951888
318.7353706359863
[1,  5500] loss: 1.972254
350.3097298145294
[1,  6000] loss: 1.927549
382.04386711120605
[1,  6500] loss: 1.856369
413.9036560058594
[1,  7000] loss: 1.864018
445.83473467826843
[1,  7500] loss: 1.818642
477.7440547943115
[1,  8000] loss: 1.802057
509.52171063423157
[1,  8500] loss: 1.755316
541.094206571579
[1,  9000] loss: 1.756169
572.9780430793762
[1,  9500] loss: 1.698652
604.7431960105896
[1, 10000] loss: 1.741149
636.5279049873352
[1, 10500] loss: 1.677974
668.6405746936798
[1, 11000] loss: 1.711702
700.5478277206421
[1, 11500] loss: 1.693874
732.2995979785919
[1, 12000] loss: 1.651706
764.3037967681885
[1, 12500] loss: 1.643618
796.0985724925995
Epoch [1] loss: 6284092.169306
[2,   500] loss: 1.589964
828.5505697727203
[2,  1000] loss: 1.558072
860.4826529026031
[2,  1500] loss: 1.569350
892.4176707267761
[2,  2000] loss: 1.566896
924.2865500450134
[2,  2500] loss: 1.563500
956.3571882247925
[2,  3000] loss: 1.543406
988.1804037094116
[2,  3500] loss: 1.599044
1020.0218920707703
[2,  4000] loss: 1.563044
1051.4500424861908
[2,  4500] loss: 1.587708
1082.9060802459717
[2,  5000] loss: 1.504541
1114.8096997737885
[2,  5500] loss: 1.534883
1146.6585836410522
[2,  6000] loss: 1.478421
1178.221420288086
[2,  6500] loss: 1.629680
1210.3563446998596
[2,  7000] loss: 1.557156
1242.1364657878876
[2,  7500] loss: 1.528481
1273.96581864357
[2,  8000] loss: 1.434423
1305.7009468078613
[2,  8500] loss: 1.469177
1337.4794709682465
[2,  9000] loss: 1.494089
1369.2891716957092
[2,  9500] loss: 1.478028
1401.0625474452972
[2, 10000] loss: 1.464012
1432.7480926513672
[2, 10500] loss: 1.424760
1464.7092740535736
[2, 11000] loss: 1.456044
1496.7298529148102
[2, 11500] loss: 1.391600
1528.444777727127
[2, 12000] loss: 1.461279
1560.257785320282
[2, 12500] loss: 1.536644
1591.803305387497
Epoch [2] loss: 4768799.846242
[3,   500] loss: 1.474018
1623.7002007961273
[3,  1000] loss: 1.420411
1655.403706073761
[3,  1500] loss: 1.408479
1687.0859377384186
[3,  2000] loss: 1.461046
1718.8603658676147
[3,  2500] loss: 1.362817
1750.6188507080078
[3,  3000] loss: 1.374245
1782.6769831180573
[3,  3500] loss: 1.401082
1814.3276340961456
[3,  4000] loss: 1.374888
1846.0264737606049
[3,  4500] loss: 1.427273
1877.768367767334
[3,  5000] loss: 1.443709
1909.530817270279
[3,  5500] loss: 1.436794
1941.2726697921753
[3,  6000] loss: 1.481050
1973.0025038719177
[3,  6500] loss: 1.392620
2004.7582173347473
[3,  7000] loss: 1.430866
2036.6225209236145
[3,  7500] loss: 1.347476
2068.497482061386
[3,  8000] loss: 1.350511
2100.214029312134
[3,  8500] loss: 1.373902
2131.7398829460144
[3,  9000] loss: 1.412171
2163.544372320175
[3,  9500] loss: 1.693319
2195.106212377548
[3, 10000] loss: 1.589498
2226.833479642868
[3, 10500] loss: 1.737380
2258.664808988571
[3, 11000] loss: 1.918729
2290.527285337448
[3, 11500] loss: 2.023992
2322.438024044037
[3, 12000] loss: 1.871935
2354.1086764335632
[3, 12500] loss: 1.956277
2386.1615896224976
Epoch [3] loss: 4739663.190432
[4,   500] loss: 2.042363
2417.9171075820923
[4,  1000] loss: 1.990778
2449.7153861522675
[4,  1500] loss: 1.943505
2481.564764738083
[4,  2000] loss: 1.932673
2513.232588291168
[4,  2500] loss: 1.912535
2544.791787147522
[4,  3000] loss: 1.866209
2576.328966856003
[4,  3500] loss: 1.836741
2608.0515851974487
[4,  4000] loss: 1.888108
2639.665618658066
[4,  4500] loss: 1.925137
2671.441482067108
[4,  5000] loss: 1.989589
2703.2736682891846
[4,  5500] loss: 1.938894
2734.8443331718445
[4,  6000] loss: 1.933412
2766.732220888138
[4,  6500] loss: 1.902389
2798.598480939865
[4,  7000] loss: 1.869237
2830.876311779022
[4,  7500] loss: 1.862894
2862.857930660248
[4,  8000] loss: 1.839804
2894.8265104293823
[4,  8500] loss: 1.794535
2927.430837869644
[4,  9000] loss: 1.788187
2959.0023155212402
[4,  9500] loss: 1.858992
2990.881962776184
[4, 10000] loss: 1.776348
3023.1685824394226
[4, 10500] loss: 1.776583
3055.1657853126526
[4, 11000] loss: 1.741512
3086.838944911957
[4, 11500] loss: 1.728254
3118.6519770622253
[4, 12000] loss: 1.776524
3150.381553888321
[4, 12500] loss: 1.777918
3182.134580850601
Epoch [4] loss: 5854292.554794
[5,   500] loss: 1.747612
3214.3432586193085
[5,  1000] loss: 1.729388
3246.0316224098206
[5,  1500] loss: 1.764845
3277.757989883423
[5,  2000] loss: 1.747906
3310.2511947155
[5,  2500] loss: 1.707692
3342.022879600525
[5,  3000] loss: 1.680972
3373.7180778980255
[5,  3500] loss: 1.721392
3405.5315461158752
[5,  4000] loss: 1.729864
3437.355346441269
[5,  4500] loss: 1.696937
3469.057242870331
[5,  5000] loss: 1.733763
3501.08460354805
[5,  5500] loss: 1.784780
3532.7412264347076
[5,  6000] loss: 1.698936
3564.57062792778
[5,  6500] loss: 1.707042
3596.1509771347046
[5,  7000] loss: 1.712136
3627.8323998451233
[5,  7500] loss: 1.671603
3659.4871311187744
[5,  8000] loss: 1.746734
3691.3760499954224
[5,  8500] loss: 1.676021
3723.47860789299
[5,  9000] loss: 1.740885
3755.4915447235107
[5,  9500] loss: 1.649526
3787.1908926963806
[5, 10000] loss: 1.786370
3819.106826066971
[5, 10500] loss: 1.722841
3851.1196613311768
[5, 11000] loss: 1.675393
3883.028571844101
[5, 11500] loss: 1.695315
3919.69388794899
[5, 12000] loss: 1.660722
3951.9849936962128
[5, 12500] loss: 1.645186
3984.071197986603
Epoch [5] loss: 5378451.250501
[6,   500] loss: 1.678695
4017.820105075836
[6,  1000] loss: 1.618154
4049.606897830963
[6,  1500] loss: 1.614939
4082.0176634788513
[6,  2000] loss: 1.594700
4113.768461942673
[6,  2500] loss: 1.615097
4145.406682729721
[6,  3000] loss: 1.574001
4177.183676242828
[6,  3500] loss: 1.585222
4208.8359270095825
[6,  4000] loss: 1.585561
4240.673725605011
[6,  4500] loss: 1.591426
4272.799718141556
[6,  5000] loss: 1.559029
4304.917155981064
[6,  5500] loss: 1.549977
4336.48543548584
[6,  6000] loss: 1.537365
4368.276703834534
[6,  6500] loss: 1.515212
4400.088653564453
[6,  7000] loss: 1.495667
4431.728752851486
[6,  7500] loss: 1.571645
4463.41620516777
[6,  8000] loss: 1.509859
4495.675795793533
[6,  8500] loss: 1.518687
4527.78665137291
[6,  9000] loss: 1.517753
4559.455534934998
[6,  9500] loss: 1.514167
4591.101403713226
[6, 10000] loss: 1.466304
4623.091283559799
[6, 10500] loss: 1.728903
4655.720111131668
[6, 11000] loss: 1.753825
4687.345565795898
[6, 11500] loss: 1.669957
4719.364867448807
[6, 12000] loss: 1.690952
4751.626845836639
[6, 12500] loss: 1.632041
4783.872868776321
Epoch [6] loss: 4964578.425135
[7,   500] loss: 1.625877
4816.0607380867
[7,  1000] loss: 1.608546
4847.840803146362
[7,  1500] loss: 1.647443
4879.479075193405
[7,  2000] loss: 1.569400
4911.254918575287
[7,  2500] loss: 1.559303
4944.063462257385
[7,  3000] loss: 1.537450
4976.723347902298
[7,  3500] loss: 1.553997
5009.902782201767
[7,  4000] loss: 1.517136
5042.630642175674
[7,  4500] loss: 1.527194
5075.760262489319
[7,  5000] loss: 1.490619
5109.353823423386
[7,  5500] loss: 1.568403
5141.491145372391
[7,  6000] loss: 1.607458
5173.403939247131
[7,  6500] loss: 1.532075
5205.109556674957
[7,  7000] loss: 1.589197
5236.745516777039
[7,  7500] loss: 2.027698
5268.488988399506
[7,  8000] loss: 2.013272
5300.694995880127
[7,  8500] loss: 1.931212
5332.818603515625
[7,  9000] loss: 1.872901
5364.529809951782
[7,  9500] loss: 1.868615
5396.299968957901
[7, 10000] loss: 1.817601
5428.109974622726
[7, 10500] loss: 1.781953
5459.7643320560455
[7, 11000] loss: 1.784953
5491.690665960312
[7, 11500] loss: 1.818267
5523.419091701508
[7, 12000] loss: 1.824312
5555.703516244888
[7, 12500] loss: 1.932101
5587.397319793701
Epoch [7] loss: 5336393.591590
[8,   500] loss: 1.931602
5619.079179048538
[8,  1000] loss: 1.849824
5650.790536403656
[8,  1500] loss: 1.800130
5682.109685897827
[8,  2000] loss: 1.815740
5713.671920537949
[8,  2500] loss: 1.756177
5745.457020998001
[8,  3000] loss: 1.787890
5777.667457103729
[8,  3500] loss: 1.799604
5809.563817739487
[8,  4000] loss: 1.767839
5841.182641506195
[8,  4500] loss: 1.755742
5872.844598531723
[8,  5000] loss: 1.715053
5904.604684352875
[8,  5500] loss: 1.718208
5936.2444858551025
[8,  6000] loss: 1.690260
5968.082343816757
[8,  6500] loss: 1.703325
5999.552077054977
[8,  7000] loss: 1.667106
6031.339400053024
[8,  7500] loss: 1.649082
6063.004295349121
[8,  8000] loss: 1.659211
6094.7866241931915
[8,  8500] loss: 1.641401
6126.869544267654
[8,  9000] loss: 1.609449
6158.6042149066925
[8,  9500] loss: 1.626402
6190.441946029663
[8, 10000] loss: 1.603300
6222.159994125366
[8, 10500] loss: 1.586760
6253.7819702625275
[8, 11000] loss: 1.623173
6285.784406423569
[8, 11500] loss: 1.573294
6317.407323360443
[8, 12000] loss: 1.596428
6349.076704502106
[8, 12500] loss: 1.581653
6380.92521071434
Epoch [8] loss: 5327350.507477
[9,   500] loss: 1.582592
6413.236679077148
[9,  1000] loss: 1.552736
6444.851473331451
[9,  1500] loss: 1.541785
6477.402544260025
[9,  2000] loss: 1.561378
6509.019418954849
[9,  2500] loss: 1.519639
6540.619453907013
[9,  3000] loss: 1.563208
6572.447284221649
[9,  3500] loss: 1.524105
6604.984263420105
[9,  4000] loss: 1.560192
6636.947060346603
[9,  4500] loss: 1.584412
6668.7570695877075
[9,  5000] loss: 1.554571
6700.396333456039
[9,  5500] loss: 1.549018
6732.213049411774
[9,  6000] loss: 1.499050
6764.534738302231
[9,  6500] loss: 1.507894
6796.354593753815
[9,  7000] loss: 1.515879
6828.2431807518005
[9,  7500] loss: 1.509203
6860.251118421555
[9,  8000] loss: 1.514811
6891.952102661133
[9,  8500] loss: 1.504171
6923.642044782639
[9,  9000] loss: 1.535916
6955.460989952087
[9,  9500] loss: 1.580446
6987.205800533295
[9, 10000] loss: 1.585561
7018.909113645554
[9, 10500] loss: 1.599116
7051.046365976334
[9, 11000] loss: 1.570075
7082.647224903107
[9, 11500] loss: 1.535308
7114.5027549266815
[9, 12000] loss: 1.505662
7146.383858203888
[9, 12500] loss: 1.516718
7178.050814151764
Epoch [9] loss: 4847676.094106
[10,   500] loss: 1.519574
7210.215554475784
[10,  1000] loss: 1.581068
7242.083273887634
[10,  1500] loss: 1.639110
7273.681650400162
[10,  2000] loss: 1.588134
7305.528113126755
[10,  2500] loss: 1.623092
7337.048411846161
[10,  3000] loss: 1.579661
7368.944858074188
[10,  3500] loss: 1.508804
7400.642630577087
[10,  4000] loss: 1.544007
7432.422396659851
[10,  4500] loss: 1.468923
7464.616819381714
[10,  5000] loss: 1.481346
7496.201807975769
[10,  5500] loss: 1.501512
7528.110968828201
[10,  6000] loss: 1.516957
7560.275958299637
[10,  6500] loss: 1.481757
7592.121604204178
[10,  7000] loss: 1.553000
7623.812636852264
[10,  7500] loss: 1.696652
7655.949229001999
[10,  8000] loss: 1.595845
7687.712083101273
[10,  8500] loss: 1.571890
7719.40295124054
[10,  9000] loss: 1.610105
7750.940937995911
[10,  9500] loss: 1.591774
7782.763692617416
[10, 10000] loss: 1.629094
7815.3877873420715
[10, 10500] loss: 1.627963
7846.991246938705
[10, 11000] loss: 1.592908
7878.649798870087
[10, 11500] loss: 1.631937
7914.549258232117
[10, 12000] loss: 1.610533
7946.237785816193
[10, 12500] loss: 1.558778
7977.926775693893
Epoch [10] loss: 4946792.126717
[11,   500] loss: 1.550585
8011.097874164581
[11,  1000] loss: 1.568805
8043.1386687755585
[11,  1500] loss: 1.545425
8075.185966730118
[11,  2000] loss: 1.670208
8107.415452241898
[11,  2500] loss: 1.595782
8138.981494665146
[11,  3000] loss: 1.586124
8171.430778741837
[11,  3500] loss: 1.595297
8203.091876745224
[11,  4000] loss: 1.621232
8235.084760427475
[11,  4500] loss: 1.533197
8266.955338716507
[11,  5000] loss: 1.583223
8298.894320726395
[11,  5500] loss: 1.535220
8330.975901126862
[11,  6000] loss: 1.553573
8363.077469348907
[11,  6500] loss: 1.477487
8394.691398382187
[11,  7000] loss: 1.531702
8426.583541154861
[11,  7500] loss: 1.473810
8458.348390817642
[11,  8000] loss: 1.517792
8490.390140533447
[11,  8500] loss: 1.487605
8522.271915435791
[11,  9000] loss: 1.531389
8553.967347621918
[11,  9500] loss: 1.525252
8585.616148471832
[11, 10000] loss: 1.545545
8617.77376461029
[11, 10500] loss: 1.496309
8649.810806751251
[11, 11000] loss: 1.494875
8681.537292718887
[11, 11500] loss: 1.490825
8713.361708402634
[11, 12000] loss: 1.488811
8745.162406682968
[11, 12500] loss: 1.451979
8776.905969619751
Epoch [11] loss: 4814307.418777
[12,   500] loss: 1.450407
8808.78899383545
[12,  1000] loss: 1.488889
8840.534309864044
[12,  1500] loss: 1.543445
8872.0829808712
[12,  2000] loss: 1.564790
8904.190838813782
[12,  2500] loss: 1.472884
8936.197498321533
[12,  3000] loss: 1.471324
8968.039345264435
[12,  3500] loss: 1.502993
8999.62089562416
[12,  4000] loss: 1.483456
9031.496843099594
[12,  4500] loss: 1.506098
9063.173937797546
[12,  5000] loss: 1.485790
9095.593061447144
[12,  5500] loss: 1.436989
9127.396250486374
[12,  6000] loss: 1.441860
9159.164046525955
[12,  6500] loss: 1.383397
9191.138102531433
[12,  7000] loss: 1.367811
9223.137857675552
[12,  7500] loss: 1.413343
9255.131400346756
[12,  8000] loss: 1.420370
9286.64898443222
[12,  8500] loss: 1.449962
9318.49434375763
[12,  9000] loss: 1.449532
9350.284710884094
[12,  9500] loss: 1.420563
9381.988169193268
[12, 10000] loss: 1.395840
9413.572663545609
[12, 10500] loss: 1.390199
9445.422783851624
[12, 11000] loss: 1.403119
9477.304711341858
[12, 11500] loss: 1.421755
9509.669986486435
[12, 12000] loss: 1.335353
9541.846922159195
[12, 12500] loss: 1.393262
9573.817460298538
Epoch [12] loss: 4522503.527550
[13,   500] loss: 1.422960
9605.892877340317
[13,  1000] loss: 1.409250
9637.599442720413
[13,  1500] loss: 1.363729
9669.557898283005
[13,  2000] loss: 1.381243
9701.580676317215
[13,  2500] loss: 1.379508
9733.332206726074
[13,  3000] loss: 1.361282
9765.294138431549
[13,  3500] loss: 1.337152
9797.182995796204
[13,  4000] loss: 1.319773
9829.002574920654
[13,  4500] loss: 1.338447
9860.7689371109
[13,  5000] loss: 1.409140
9892.474339962006
[13,  5500] loss: 1.369212
9924.350247383118
[13,  6000] loss: 1.382614
9956.235482692719
[13,  6500] loss: 1.457046
9988.395927667618
[13,  7000] loss: 1.460836
10020.622161388397
[13,  7500] loss: 1.444056
10052.71831035614
[13,  8000] loss: 1.426147
10084.882132053375
[13,  8500] loss: 1.353587
10116.863263607025
[13,  9000] loss: 1.435616
10148.766683340073
[13,  9500] loss: 1.438897
10180.679759263992
[13, 10000] loss: 1.475640
10212.573261499405
[13, 10500] loss: 1.373742
10244.337621212006
[13, 11000] loss: 1.399800
10276.355815887451
[13, 11500] loss: 1.374764
10308.122735023499
[13, 12000] loss: 1.371169
10340.550384998322
[13, 12500] loss: 1.374583
10372.530134916306
Epoch [13] loss: 4362059.245817
[14,   500] loss: 1.318919
10404.536890983582
[14,  1000] loss: 1.339635
10436.235679388046
[14,  1500] loss: 1.344060
10468.428421497345
[14,  2000] loss: 1.375554
10500.310236692429
[14,  2500] loss: 1.378318
10532.384532690048
[14,  3000] loss: 1.346844
10563.987872838974
[14,  3500] loss: 1.295762
10595.84217429161
[14,  4000] loss: 1.365068
10628.36167216301
[14,  4500] loss: 1.354435
10660.510789632797
[14,  5000] loss: 1.348815
10692.68936085701
[14,  5500] loss: 1.316525
10724.474394321442
[14,  6000] loss: 1.319993
10756.250177383423
[14,  6500] loss: 1.430295
10788.290091276169
[14,  7000] loss: 1.383680
10820.05663394928
[14,  7500] loss: 1.404585
10852.088936567307
[14,  8000] loss: 1.390806
10884.05546617508
[14,  8500] loss: 1.391246
10915.77931880951
[14,  9000] loss: 1.418216
10947.52998304367
[14,  9500] loss: 1.421655
10979.382114887238
[14, 10000] loss: 1.368037
11011.097462415695
[14, 10500] loss: 1.440344
11042.790627002716
[14, 11000] loss: 1.409089
11074.796517133713
[14, 11500] loss: 1.457821
11107.08693742752
[14, 12000] loss: 1.348686
11138.838341236115
[14, 12500] loss: 1.408802
11170.56057190895
Epoch [14] loss: 4294920.938856
[15,   500] loss: 1.379985
11202.33375453949
[15,  1000] loss: 1.385278
11234.18979048729
[15,  1500] loss: 1.382743
11265.870883226395
[15,  2000] loss: 1.338673
11297.763850688934
[15,  2500] loss: 1.376636
11329.628736257553
[15,  3000] loss: 1.333395
11361.333108901978
[15,  3500] loss: 1.377524
11392.914503097534
[15,  4000] loss: 1.354554
11424.823438882828
[15,  4500] loss: 1.322575
11456.40124464035
[15,  5000] loss: 1.306691
11488.891725063324
[15,  5500] loss: 1.352942
11520.928423643112
[15,  6000] loss: 1.317177
11552.644290685654
[15,  6500] loss: 1.317828
11584.491687297821
[15,  7000] loss: 1.315557
11616.381120443344
[15,  7500] loss: 1.347620
11648.201749324799
[15,  8000] loss: 1.310091
11680.160901069641
[15,  8500] loss: 1.349114
11711.950073003769
[15,  9000] loss: 1.279220
11746.100451469421
[15,  9500] loss: 1.336891
11778.109227180481
[15, 10000] loss: 1.272209
11810.07956957817
[15, 10500] loss: 1.310564
11842.055568218231
[15, 11000] loss: 1.331007
11873.936671733856
[15, 11500] loss: 1.307241
11905.916862726212
[15, 12000] loss: 1.322287
11937.710200548172
[15, 12500] loss: 1.345015
11969.443264007568
Epoch [15] loss: 4190432.905086
[16,   500] loss: 1.225033
12001.655068159103
[16,  1000] loss: 1.257241
12033.43865609169
[16,  1500] loss: 1.243982
12065.21021080017
[16,  2000] loss: 1.310941
12097.490262269974
[16,  2500] loss: 1.265789
12129.094444990158
[16,  3000] loss: 1.275481
12160.964901208878
[16,  3500] loss: 1.284605
12192.916041612625
[16,  4000] loss: 1.277848
12224.695058107376
[16,  4500] loss: 1.294616
12256.694972276688
[16,  5000] loss: 1.300855
12288.949288606644
[16,  5500] loss: 1.277105
12320.711783647537
[16,  6000] loss: 1.306800
12352.354920625687
[16,  6500] loss: 1.226224
12383.862374067307
[16,  7000] loss: 1.281705
12415.69733285904
[16,  7500] loss: 1.432233
12448.509255886078
[16,  8000] loss: 1.364888
12480.29794216156
[16,  8500] loss: 1.400745
12512.1835770607
[16,  9000] loss: 1.307637
12543.924978733063
[16,  9500] loss: 1.355295
12575.642815589905
[16, 10000] loss: 1.363093
12608.00046157837
[16, 10500] loss: 1.325076
12639.654069423676
[16, 11000] loss: 1.274452
12671.345516443253
[16, 11500] loss: 1.312785
12703.762676477432
[16, 12000] loss: 1.277100
12735.447410821915
[16, 12500] loss: 1.336901
12767.693280696869
Epoch [16] loss: 4082137.725377
[17,   500] loss: 1.558218
12801.527987241745
[17,  1000] loss: 1.573169
12834.125264644623
[17,  1500] loss: 1.515716
12866.040351629257
[17,  2000] loss: 1.452805
12897.66739654541
[17,  2500] loss: 1.399820
12929.76728963852
[17,  3000] loss: 1.398567
12961.966366529465
[17,  3500] loss: 1.413625
12993.706874132156
[17,  4000] loss: 1.375649
13025.47781920433
[17,  4500] loss: 1.361048
13057.588759422302
[17,  5000] loss: 1.320474
13089.919541358948
[17,  5500] loss: 1.334175
13121.996592760086
[17,  6000] loss: 1.340677
13154.442160367966
[17,  6500] loss: 1.258452
13186.414663553238
[17,  7000] loss: 1.278188
13218.622943878174
[17,  7500] loss: 1.328673
13250.19699716568
[17,  8000] loss: 1.287354
13281.82699894905
[17,  8500] loss: 1.292852
13313.52886915207
[17,  9000] loss: 1.254136
13345.349073410034
[17,  9500] loss: 1.306096
13376.972743749619
[17, 10000] loss: 1.247134
13408.790539979935
[17, 10500] loss: 1.323671
13440.519478082657
[17, 11000] loss: 1.296345
13473.115293264389
[17, 11500] loss: 1.280917
13504.942959547043
[17, 12000] loss: 1.287873
13537.128255367279
[17, 12500] loss: 1.250093
13569.039194822311
Epoch [17] loss: 4235489.724770
[18,   500] loss: 1.275981
13601.078197717667
[18,  1000] loss: 1.248218
13633.434790372849
[18,  1500] loss: 1.238855
13665.375972032547
[18,  2000] loss: 1.247536
13697.019338130951
[18,  2500] loss: 1.281582
13728.759004592896
[18,  3000] loss: 1.191813
13760.735212564468
[18,  3500] loss: 1.227053
13792.612917900085
[18,  4000] loss: 1.234691
13824.678181648254
[18,  4500] loss: 1.205889
13856.566450834274
[18,  5000] loss: 1.187330
13888.283225774765
[18,  5500] loss: 1.253828
13920.025742292404
[18,  6000] loss: 1.250914
13952.183008909225
[18,  6500] loss: 1.258117
13985.020839691162
[18,  7000] loss: 1.192896
14017.29133272171
[18,  7500] loss: 1.248439
14050.440729856491
[18,  8000] loss: 1.219861
14082.162187099457
[18,  8500] loss: 1.183388
14114.146396398544
[18,  9000] loss: 1.200562
14146.81940150261
[18,  9500] loss: 1.277460
14179.076115608215
[18, 10000] loss: 1.167577
14211.325515031815
[18, 10500] loss: 1.230882
14243.582810878754
[18, 11000] loss: 1.319382
14275.87823009491
[18, 11500] loss: 1.269356
14308.404854536057
[18, 12000] loss: 1.296074
14340.523428678513
[18, 12500] loss: 1.258296
14372.738540410995
Epoch [18] loss: 3897333.972844
[19,   500] loss: 1.302444
14405.457384586334
[19,  1000] loss: 1.275934
14438.056700706482
[19,  1500] loss: 1.279575
14470.430476427078
[19,  2000] loss: 1.431810
14502.717235326767
[19,  2500] loss: 1.446565
14535.219573020935
[19,  3000] loss: 1.371268
14567.637961149216
[19,  3500] loss: 1.349613
14599.87873005867
[19,  4000] loss: 1.445391
14632.547728300095
[19,  4500] loss: 1.405748
14665.330323457718
[19,  5000] loss: 1.390681
14698.092137813568
[19,  5500] loss: 1.341346
14730.405001401901
[19,  6000] loss: 1.331514
14762.945205688477
[19,  6500] loss: 1.351431
14795.408086299896
[19,  7000] loss: 1.371101
14828.906484603882
[19,  7500] loss: 1.350518
14861.200427532196
[19,  8000] loss: 1.356611
14893.145550727844
[19,  8500] loss: 1.477127
14925.80387210846
[19,  9000] loss: 1.446980
14958.05829334259
[19,  9500] loss: 1.408984
14990.487137317657
[19, 10000] loss: 1.474595
15023.13767695427
[19, 10500] loss: 1.460142
15055.354880809784
[19, 11000] loss: 1.406342
15087.910912275314
[19, 11500] loss: 1.319303
15120.382031440735
[19, 12000] loss: 1.370760
15152.988667726517
[19, 12500] loss: 1.292125
15186.44718003273
Epoch [19] loss: 4313557.331846
[20,   500] loss: 1.343513
15219.274440526962
[20,  1000] loss: 1.331408
15252.007150888443
[20,  1500] loss: 1.294289
15284.8130569458
[20,  2000] loss: 1.292282
15317.355572938919
[20,  2500] loss: 1.268870
15350.160115480423
[20,  3000] loss: 1.526303
15382.61856675148
[20,  3500] loss: 1.377979
15415.484374046326
[20,  4000] loss: 1.355351
15448.371255397797
[20,  4500] loss: 1.450429
15480.48878288269
[20,  5000] loss: 1.394430
15512.563871145248
[20,  5500] loss: 1.342651
15544.884320497513
[20,  6000] loss: 1.322683
15577.116839647293
[20,  6500] loss: 1.298219
15609.503636598587
[20,  7000] loss: 1.310637
15643.164177179337
[20,  7500] loss: 1.373409
15675.437644958496
[20,  8000] loss: 1.364470
15708.359283447266
[20,  8500] loss: 1.320062
15742.0846722126
[20,  9000] loss: 1.279463
15775.698456764221
[20,  9500] loss: 1.330888
15809.397311925888
[20, 10000] loss: 1.371485
15841.900804519653
[20, 10500] loss: 1.356892
15874.950407028198
[20, 11000] loss: 1.291282
15907.430495977402
[20, 11500] loss: 1.331829
15939.850438117981
[20, 12000] loss: 1.250978
15972.334324836731
[20, 12500] loss: 1.290772
16005.087419986725
Epoch [20] loss: 4205580.915294
Finished Training
Saving model to /data/s4091221/trained-models/densenet1212020-02-25 06:05:01.859667
GroundTruth:    cat  ship  ship plane
Sending data to GPU
Sending model to GPU
tensor([[ 9.4956,  8.8261, 11.2204,  ...,  0.5360,  1.1660,  1.4724],
        [14.2710, 15.2682, 11.2419,  ...,  0.6958,  0.3705,  0.4036],
        [12.9932, 12.9359, 10.6287,  ...,  1.2681,  1.3689,  0.7800],
        [14.4131, 12.2894, 13.1434,  ...,  0.1990,  1.0362,  0.6434]],
       device='cuda:0', grad_fn=<AddmmBackward>)
Predicted:    cat  ship  ship  ship
Accuracy of the network on the 4000.0 test images: 52 %


###############################################################################
Peregrine Cluster
Job 9730755 for user 's4091221'
Finished at: Tue Feb 25 06:06:06 CET 2020

Job details:
============

Name                : densenet121.sh
User                : s4091221
Partition           : gpu
Nodes               : pg-gpu37
Cores               : 12
State               : COMPLETED
Submit              : 2020-02-24T18:00:31
Start               : 2020-02-24T21:01:02
End                 : 2020-02-25T06:06:06
Reserved walltime   : 15:00:00
Used walltime       : 09:05:04
Used CPU time       : 09:18:26 (efficiency:  8.54%)
% User (Computation): 98.83%
% System (I/O)      :  1.17%
Mem reserved        : 12000M/node
Max Mem used        : 2.91G (pg-gpu37)
Max Disk Write      : 215.91M (pg-gpu37)
Max Disk Read       : 1.06G (pg-gpu37)


Acknowledgements:
=================

Please see this page for information about acknowledging Peregrine in your publications:

https://wiki.hpc.rug.nl/peregrine/additional_information/scientific_output

################################################################################
